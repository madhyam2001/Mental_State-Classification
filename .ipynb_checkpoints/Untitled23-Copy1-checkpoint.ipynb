{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e99e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b70f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "data_new= pd.get_dummies(df, columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f7e9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>15.762328</td>\n",
       "      <td>19.113555</td>\n",
       "      <td>23.696867</td>\n",
       "      <td>7.568395</td>\n",
       "      <td>-6.503336</td>\n",
       "      <td>6.867187</td>\n",
       "      <td>-11.955396</td>\n",
       "      <td>-16.519912</td>\n",
       "      <td>19.838319</td>\n",
       "      <td>14.333094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>34.675582</td>\n",
       "      <td>34.200645</td>\n",
       "      <td>-57.624820</td>\n",
       "      <td>-4.825609</td>\n",
       "      <td>7.382353</td>\n",
       "      <td>2.324416</td>\n",
       "      <td>-1.341208</td>\n",
       "      <td>-4.178625</td>\n",
       "      <td>26.383597</td>\n",
       "      <td>28.782987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>29.813809</td>\n",
       "      <td>29.623031</td>\n",
       "      <td>-86.503988</td>\n",
       "      <td>7.532121</td>\n",
       "      <td>-19.581287</td>\n",
       "      <td>-0.628400</td>\n",
       "      <td>133.947160</td>\n",
       "      <td>-2.049096</td>\n",
       "      <td>45.484851</td>\n",
       "      <td>32.163999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>59.453973</td>\n",
       "      <td>17.944332</td>\n",
       "      <td>-10.164238</td>\n",
       "      <td>42.568211</td>\n",
       "      <td>-1.300655</td>\n",
       "      <td>-19.993690</td>\n",
       "      <td>-54.331696</td>\n",
       "      <td>12.947622</td>\n",
       "      <td>55.203380</td>\n",
       "      <td>40.228490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>22.893855</td>\n",
       "      <td>30.412723</td>\n",
       "      <td>26.029590</td>\n",
       "      <td>14.249789</td>\n",
       "      <td>-7.101478</td>\n",
       "      <td>-0.551013</td>\n",
       "      <td>3.735563</td>\n",
       "      <td>-9.372750</td>\n",
       "      <td>30.411574</td>\n",
       "      <td>30.079904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0       25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1       29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2       28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3       21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4       20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "...           ...          ...          ...          ...                 ...   \n",
       "2474    15.762328    19.113555    23.696867     7.568395           -6.503336   \n",
       "2475    34.675582    34.200645   -57.624820    -4.825609            7.382353   \n",
       "2476    29.813809    29.623031   -86.503988     7.532121          -19.581287   \n",
       "2477    59.453973    17.944332   -10.164238    42.568211           -1.300655   \n",
       "2478    22.893855    30.412723    26.029590    14.249789           -7.101478   \n",
       "\n",
       "      lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "0               0.197462         -119.561133            2.032654   \n",
       "1             -16.897194          -29.368531           -9.055370   \n",
       "2              -0.614138          -28.331698           -8.858742   \n",
       "3               0.670216           -1.820355           20.220724   \n",
       "4              -6.020503           -1.071166            2.655259   \n",
       "...                  ...                 ...                 ...   \n",
       "2474            6.867187          -11.955396          -16.519912   \n",
       "2475            2.324416           -1.341208           -4.178625   \n",
       "2476           -0.628400          133.947160           -2.049096   \n",
       "2477          -19.993690          -54.331696           12.947622   \n",
       "2478           -0.551013            3.735563           -9.372750   \n",
       "\n",
       "      lag1_mean_q1_0  lag1_mean_q1_1  ...  freq_689_3  freq_699_3  freq_709_3  \\\n",
       "0          21.596272       33.965587  ...    0.000547    0.000381    0.000350   \n",
       "1          44.647424       40.893307  ...    0.001122    0.000521    0.000624   \n",
       "2          31.450289       30.692883  ...    0.000327    0.000197    0.000833   \n",
       "3          21.404679       20.777411  ...    0.006891    0.010546    0.009583   \n",
       "4          16.295039       32.658163  ...    0.014492    0.002949    0.004575   \n",
       "...              ...             ...  ...         ...         ...         ...   \n",
       "2474       19.838319       14.333094  ...    0.004102    0.003156    0.003659   \n",
       "2475       26.383597       28.782987  ...    0.001702    0.003121    0.002686   \n",
       "2476       45.484851       32.163999  ...    0.000263    0.000701    0.000797   \n",
       "2477       55.203380       40.228490  ...    0.004063    0.001662    0.002665   \n",
       "2478       30.411574       30.079904  ...    0.002528    0.005357    0.004612   \n",
       "\n",
       "      freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label_0.0  Label_1.0  \\\n",
       "0       0.000453    0.000442    0.000325    0.000209          0          0   \n",
       "1       0.000439    0.001249    0.000727    0.000801          0          0   \n",
       "2       0.000909    0.000699    0.001165    0.000616          0          0   \n",
       "3       0.011158    0.008853    0.004551    0.002287          0          1   \n",
       "4       0.008305    0.007202    0.006957    0.009836          0          0   \n",
       "...          ...         ...         ...         ...        ...        ...   \n",
       "2474    0.010179    0.004591    0.013817    0.004536          1          0   \n",
       "2475    0.001645    0.001770    0.001038    0.001973          0          0   \n",
       "2476    0.001096    0.000388    0.000529    0.001079          0          0   \n",
       "2477    0.002353    0.003976    0.001660    0.003229          0          0   \n",
       "2478    0.004503    0.003669    0.002316    0.004765          0          1   \n",
       "\n",
       "      Label_2.0  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "2474          0  \n",
       "2475          1  \n",
       "2476          1  \n",
       "2477          1  \n",
       "2478          0  \n",
       "\n",
       "[2479 rows x 991 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3084e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_659_3</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_659_3  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0       33.965587  ...    0.000579    0.000230    0.000351    0.000547   \n",
       "1       40.893307  ...    0.000448    0.001671    0.000740    0.001122   \n",
       "2       30.692883  ...    0.001028    0.000748    0.000569    0.000327   \n",
       "3       20.777411  ...    0.015502    0.000990    0.005644    0.006891   \n",
       "4       32.658163  ...    0.013212    0.001659    0.014379    0.014492   \n",
       "\n",
       "   freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \n",
       "0    0.000381    0.000350    0.000453    0.000442    0.000325    0.000209  \n",
       "1    0.000521    0.000624    0.000439    0.001249    0.000727    0.000801  \n",
       "2    0.000197    0.000833    0.000909    0.000699    0.001165    0.000616  \n",
       "3    0.010546    0.009583    0.011158    0.008853    0.004551    0.002287  \n",
       "4    0.002949    0.004575    0.008305    0.007202    0.006957    0.009836  \n",
       "\n",
       "[5 rows x 988 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data_new.loc[:,'lag1_mean_0':'freq_750_3']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dacd32e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label_0.0  Label_1.0  Label_2.0\n",
       "0          0          0          1\n",
       "1          0          0          1\n",
       "2          0          0          1\n",
       "3          0          1          0\n",
       "4          0          0          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data_new.loc[:,'Label_0.0':'Label_2.0']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fcb9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8d5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1d17c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components=64,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7adb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = kpca.fit_transform(X_scaled)\n",
    "df_pca = pd.concat([pd.DataFrame(X_pca), y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1ca292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.297849</td>\n",
       "      <td>0.119659</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>-0.040967</td>\n",
       "      <td>-0.031069</td>\n",
       "      <td>-0.149366</td>\n",
       "      <td>0.032674</td>\n",
       "      <td>-0.023312</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>-0.031270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036262</td>\n",
       "      <td>0.083469</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.054247</td>\n",
       "      <td>0.054909</td>\n",
       "      <td>-0.018380</td>\n",
       "      <td>-0.021884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306944</td>\n",
       "      <td>0.206340</td>\n",
       "      <td>-0.124424</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>-0.049474</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>-0.022706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.061171</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>-0.100815</td>\n",
       "      <td>0.029010</td>\n",
       "      <td>-0.035726</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.547152</td>\n",
       "      <td>-0.103030</td>\n",
       "      <td>-0.140274</td>\n",
       "      <td>-0.037888</td>\n",
       "      <td>-0.122875</td>\n",
       "      <td>-0.089208</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>-0.153586</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>-0.022968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063986</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>-0.037650</td>\n",
       "      <td>0.023296</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.258242</td>\n",
       "      <td>-0.090302</td>\n",
       "      <td>-0.015256</td>\n",
       "      <td>-0.041658</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.078394</td>\n",
       "      <td>0.017149</td>\n",
       "      <td>-0.106242</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.073247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>-0.011927</td>\n",
       "      <td>-0.058689</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004751</td>\n",
       "      <td>0.360870</td>\n",
       "      <td>0.168487</td>\n",
       "      <td>0.216504</td>\n",
       "      <td>-0.078917</td>\n",
       "      <td>0.061536</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.039856</td>\n",
       "      <td>0.011366</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.018126</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>-0.016795</td>\n",
       "      <td>-0.010428</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.297849  0.119659  0.010189 -0.040967 -0.031069 -0.149366  0.032674   \n",
       "1  0.306944  0.206340 -0.124424 -0.000305  0.035877 -0.049474 -0.034111   \n",
       "2  0.547152 -0.103030 -0.140274 -0.037888 -0.122875 -0.089208 -0.006034   \n",
       "3 -0.258242 -0.090302 -0.015256 -0.041658 -0.034132  0.078394  0.017149   \n",
       "4 -0.004751  0.360870  0.168487  0.216504 -0.078917  0.061536  0.002307   \n",
       "\n",
       "          7         8         9  ...        57        58        59        60  \\\n",
       "0 -0.023312  0.016385 -0.031270  ... -0.036262  0.083469  0.018670 -0.054247   \n",
       "1  0.002305 -0.020476 -0.022706  ...  0.019440  0.061171  0.016695 -0.100815   \n",
       "2 -0.153586  0.010439 -0.022968  ...  0.063986  0.015127 -0.002270 -0.037650   \n",
       "3 -0.106242  0.017621  0.073247  ...  0.002457  0.030505 -0.011927 -0.058689   \n",
       "4 -0.039856  0.011366  0.006206  ...  0.000478 -0.018126  0.020353 -0.016795   \n",
       "\n",
       "         61        62        63  Label_0.0  Label_1.0  Label_2.0  \n",
       "0  0.054909 -0.018380 -0.021884          0          0          1  \n",
       "1  0.029010 -0.035726  0.023559          0          0          1  \n",
       "2  0.023296  0.038561  0.037274          0          0          1  \n",
       "3  0.040897  0.056194 -0.002891          0          1          0  \n",
       "4 -0.010428 -0.007948  0.000323          0          0          1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebaac8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2479, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2ab982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label_0.0  Label_1.0  Label_2.0\n",
       "0             0          0          1\n",
       "1             0          0          1\n",
       "2             0          0          1\n",
       "3             0          1          0\n",
       "4             0          0          1\n",
       "...         ...        ...        ...\n",
       "2474          1          0          0\n",
       "2475          0          0          1\n",
       "2476          0          0          1\n",
       "2477          0          0          1\n",
       "2478          0          1          0\n",
       "\n",
       "[2479 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7aa0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c506fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6043087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5426bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_pca,y1,test_size=0.2,random_state=123)\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79b984b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "382f5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MinMaxScaler()\n",
    "t.fit(x_train)\n",
    "x_train = t.transform(x_train)\n",
    "x_val=t.transform(x_val)\n",
    "x_test = t.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc30de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a94be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_pca.shape[1]\n",
    "# define encoder\n",
    "input_data_shape= Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "encoder= Dense(n_inputs*2)(input_data_shape)\n",
    "encoder = BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# encoder level 2\n",
    "encoder= Dense(n_inputs)(encoder)\n",
    "encoder= BatchNormalization()(encoder)\n",
    "encoder= LeakyReLU()(encoder)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(encoder)\n",
    "# define decoder, level 1\n",
    "decoder = Dense(n_inputs)(bottleneck)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "# decoder level 2\n",
    "decoder = Dense(n_inputs*2)(decoder)\n",
    "decoder = BatchNormalization()(decoder)\n",
    "decoder = LeakyReLU()(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b28bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(n_inputs, activation='linear')(decoder)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=input_data_shape, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d5458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,880\n",
      "Trainable params: 38,112\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f69651a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 6s 19ms/step - loss: 0.9754 - val_loss: 1.1848\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1702 - val_loss: 0.8889\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1194 - val_loss: 0.7331\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0949 - val_loss: 0.6166\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0916 - val_loss: 0.5381\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0793 - val_loss: 0.4945\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0665 - val_loss: 0.4918\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.4734\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.4258\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0610 - val_loss: 0.4022\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0599 - val_loss: 0.4334\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0502 - val_loss: 0.3476\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0468 - val_loss: 0.3302\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0438 - val_loss: 0.3099\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.3429\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.3741\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0339 - val_loss: 0.3392\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.4132\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.4331\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.3952\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0307 - val_loss: 0.3881\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.4430\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.5495\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0385 - val_loss: 0.3657\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0314 - val_loss: 0.4045\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.4610\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.5267\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.3932\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0284 - val_loss: 0.5567\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.6222\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.6295\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.5799\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0296 - val_loss: 0.5203\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.5830\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0239 - val_loss: 0.4936\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.4352\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.6723\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.5636\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.7267\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.5716\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.6612\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.6406\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0258 - val_loss: 0.6906\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.5308\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.5821\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.5110\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.5475\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.5398\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.5705\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.5407\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50, batch_size=40, verbose=1, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84f6ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs=input_data_shape, outputs=bottleneck)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13b8a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "50/50 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model('encoder1.h5')\n",
    "\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(x_train)\n",
    "X_val_encode = encoder.predict(x_val)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c8a901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1586, 32), (397, 32), (496, 32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encode.shape, X_val_encode.shape, X_test_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62d8b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin=label_binarize(y_train,classes=np.unique(y_train))\n",
    "y_val_bin=label_binarize(y_val,classes=np.unique(y_val))\n",
    "y_test_bin=label_binarize(y_test,classes=np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a92ca5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13a2b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(64, 5, input_shape=(X_train_encode.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(64, 5,activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation='softmax'))   \n",
    "# model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = ['accuracy','auc','f1score'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ce9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbc5a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_acc') > 0.99:\n",
    "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "my_callback = MyCallback()\n",
    "\n",
    "#EarlyStopping callback to make sure model is always learning\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eeb77681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 28, 64)            384       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 28, 64)            33024     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 28, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 14, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 64)            0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 64)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 10, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 5, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 5, 64)             0         \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 5, 64)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 963       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,427\n",
      "Trainable params: 55,171\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining other parameters for our CNN model\n",
    "\n",
    "model = model\n",
    "\n",
    "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='Accuracy'),\n",
    "           tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "CALLBACKS = [my_callback]\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.CategoricalCrossentropy(),\n",
    "              metrics=METRICS)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "694b3584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "40/40 [==============================] - 9s 80ms/step - loss: 0.1372 - Accuracy: 0.9527 - AUC: 0.9949 - val_loss: 1.0403 - val_Accuracy: 0.5693 - val_AUC: 0.6846\n",
      "Epoch 2/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0292 - Accuracy: 0.9918 - AUC: 0.9995 - val_loss: 1.0356 - val_Accuracy: 0.5290 - val_AUC: 0.6733\n",
      "Epoch 3/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0206 - Accuracy: 0.9943 - AUC: 0.9996 - val_loss: 1.0320 - val_Accuracy: 0.4987 - val_AUC: 0.6661\n",
      "Epoch 4/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0197 - Accuracy: 0.9937 - AUC: 0.9999 - val_loss: 1.0133 - val_Accuracy: 0.5214 - val_AUC: 0.6666\n",
      "Epoch 5/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0180 - Accuracy: 0.9950 - AUC: 0.9999 - val_loss: 1.0235 - val_Accuracy: 0.5617 - val_AUC: 0.6737\n",
      "Epoch 6/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0209 - Accuracy: 0.9950 - AUC: 0.9994 - val_loss: 1.1228 - val_Accuracy: 0.4987 - val_AUC: 0.6610\n",
      "Epoch 7/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0167 - Accuracy: 0.9937 - AUC: 0.9999 - val_loss: 1.4214 - val_Accuracy: 0.4534 - val_AUC: 0.6368\n",
      "Epoch 8/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0185 - Accuracy: 0.9950 - AUC: 0.9999 - val_loss: 2.5776 - val_Accuracy: 0.3426 - val_AUC: 0.5880\n",
      "Epoch 9/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0180 - Accuracy: 0.9950 - AUC: 0.9995 - val_loss: 2.3484 - val_Accuracy: 0.5668 - val_AUC: 0.6297\n",
      "Epoch 10/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0172 - Accuracy: 0.9950 - AUC: 0.9999 - val_loss: 3.2983 - val_Accuracy: 0.4962 - val_AUC: 0.6275\n",
      "Epoch 11/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0121 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 3.4223 - val_Accuracy: 0.5491 - val_AUC: 0.6376\n",
      "Epoch 12/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0124 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 3.7042 - val_Accuracy: 0.5290 - val_AUC: 0.6422\n",
      "Epoch 13/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0095 - Accuracy: 0.9975 - AUC: 1.0000 - val_loss: 3.7829 - val_Accuracy: 0.5693 - val_AUC: 0.6565\n",
      "Epoch 14/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0095 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 3.4381 - val_Accuracy: 0.5466 - val_AUC: 0.6718\n",
      "Epoch 15/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0159 - Accuracy: 0.9950 - AUC: 0.9999 - val_loss: 4.1921 - val_Accuracy: 0.5516 - val_AUC: 0.6789\n",
      "Epoch 16/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0119 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.6657 - val_Accuracy: 0.5491 - val_AUC: 0.6820\n",
      "Epoch 17/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0139 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.4722 - val_Accuracy: 0.5491 - val_AUC: 0.6548\n",
      "Epoch 18/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0137 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 4.8044 - val_Accuracy: 0.5668 - val_AUC: 0.6866\n",
      "Epoch 19/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0135 - Accuracy: 0.9950 - AUC: 1.0000 - val_loss: 5.9368 - val_Accuracy: 0.5516 - val_AUC: 0.6613\n",
      "Epoch 20/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0119 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.0353 - val_Accuracy: 0.5542 - val_AUC: 0.6639\n",
      "Epoch 21/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0136 - Accuracy: 0.9943 - AUC: 1.0000 - val_loss: 5.1230 - val_Accuracy: 0.5793 - val_AUC: 0.6877\n",
      "Epoch 22/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0110 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.4006 - val_Accuracy: 0.5516 - val_AUC: 0.6599\n",
      "Epoch 23/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0144 - Accuracy: 0.9962 - AUC: 0.9996 - val_loss: 5.5202 - val_Accuracy: 0.5894 - val_AUC: 0.6802\n",
      "Epoch 24/70\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.0119 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.3839 - val_Accuracy: 0.5290 - val_AUC: 0.6818\n",
      "Epoch 25/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0110 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 6.0948 - val_Accuracy: 0.5592 - val_AUC: 0.6903\n",
      "Epoch 26/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0094 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 5.3494 - val_Accuracy: 0.5416 - val_AUC: 0.6868\n",
      "Epoch 27/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0099 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 5.6903 - val_Accuracy: 0.5491 - val_AUC: 0.6897\n",
      "Epoch 28/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0146 - Accuracy: 0.9943 - AUC: 0.9996 - val_loss: 9.9022 - val_Accuracy: 0.3703 - val_AUC: 0.5630\n",
      "Epoch 29/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0144 - Accuracy: 0.9943 - AUC: 0.9999 - val_loss: 6.2562 - val_Accuracy: 0.5793 - val_AUC: 0.6768\n",
      "Epoch 30/70\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0128 - Accuracy: 0.9943 - AUC: 1.0000 - val_loss: 4.7322 - val_Accuracy: 0.5088 - val_AUC: 0.6653\n",
      "Epoch 31/70\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0110 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.0605 - val_Accuracy: 0.5768 - val_AUC: 0.6812\n",
      "Epoch 32/70\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0132 - Accuracy: 0.9950 - AUC: 1.0000 - val_loss: 5.9934 - val_Accuracy: 0.5617 - val_AUC: 0.6915\n",
      "Epoch 33/70\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0086 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 6.8811 - val_Accuracy: 0.5793 - val_AUC: 0.6734\n",
      "Epoch 34/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0101 - Accuracy: 0.9975 - AUC: 1.0000 - val_loss: 6.5559 - val_Accuracy: 0.5768 - val_AUC: 0.6799\n",
      "Epoch 35/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0116 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 6.4752 - val_Accuracy: 0.5693 - val_AUC: 0.6849\n",
      "Epoch 36/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0111 - Accuracy: 0.9950 - AUC: 1.0000 - val_loss: 6.0229 - val_Accuracy: 0.5491 - val_AUC: 0.6893\n",
      "Epoch 37/70\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0102 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.8434 - val_Accuracy: 0.5516 - val_AUC: 0.6923\n",
      "Epoch 38/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0129 - Accuracy: 0.9943 - AUC: 1.0000 - val_loss: 6.6490 - val_Accuracy: 0.5768 - val_AUC: 0.6884\n",
      "Epoch 39/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0096 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 7.2594 - val_Accuracy: 0.5592 - val_AUC: 0.6687\n",
      "Epoch 40/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0099 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 7.0603 - val_Accuracy: 0.5617 - val_AUC: 0.6696\n",
      "Epoch 41/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0085 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.4636 - val_Accuracy: 0.5869 - val_AUC: 0.6735\n",
      "Epoch 42/70\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0103 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 6.4229 - val_Accuracy: 0.5617 - val_AUC: 0.6887\n",
      "Epoch 43/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0079 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.4222 - val_Accuracy: 0.5793 - val_AUC: 0.6747\n",
      "Epoch 44/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0083 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 5.9908 - val_Accuracy: 0.5793 - val_AUC: 0.6781\n",
      "Epoch 45/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0098 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 5.2350 - val_Accuracy: 0.5592 - val_AUC: 0.6886\n",
      "Epoch 46/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0107 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 5.6478 - val_Accuracy: 0.5491 - val_AUC: 0.6586\n",
      "Epoch 47/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0116 - Accuracy: 0.9943 - AUC: 1.0000 - val_loss: 6.0800 - val_Accuracy: 0.4836 - val_AUC: 0.6323\n",
      "Epoch 48/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0101 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.9308 - val_Accuracy: 0.5340 - val_AUC: 0.6500\n",
      "Epoch 49/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0097 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.4681 - val_Accuracy: 0.5793 - val_AUC: 0.6918\n",
      "Epoch 50/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0096 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.2102 - val_Accuracy: 0.5693 - val_AUC: 0.6612\n",
      "Epoch 51/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0095 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 4.0371 - val_Accuracy: 0.5844 - val_AUC: 0.6807\n",
      "Epoch 52/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0075 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.2634 - val_Accuracy: 0.5844 - val_AUC: 0.6714\n",
      "Epoch 53/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0104 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.6345 - val_Accuracy: 0.5793 - val_AUC: 0.6686\n",
      "Epoch 54/70\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0094 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 3.9268 - val_Accuracy: 0.5743 - val_AUC: 0.6905\n",
      "Epoch 55/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0109 - Accuracy: 0.9950 - AUC: 1.0000 - val_loss: 3.7763 - val_Accuracy: 0.5139 - val_AUC: 0.6720\n",
      "Epoch 56/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0092 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 3.6458 - val_Accuracy: 0.5139 - val_AUC: 0.6687\n",
      "Epoch 57/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0085 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 4.8944 - val_Accuracy: 0.5819 - val_AUC: 0.6740\n",
      "Epoch 58/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0097 - Accuracy: 0.9950 - AUC: 1.0000 - val_loss: 5.5022 - val_Accuracy: 0.5290 - val_AUC: 0.6509\n",
      "Epoch 59/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0121 - Accuracy: 0.9943 - AUC: 1.0000 - val_loss: 6.0206 - val_Accuracy: 0.4509 - val_AUC: 0.6258\n",
      "Epoch 60/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0083 - Accuracy: 0.9968 - AUC: 1.0000 - val_loss: 6.2813 - val_Accuracy: 0.4861 - val_AUC: 0.6335\n",
      "Epoch 61/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0091 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 8.6880 - val_Accuracy: 0.3753 - val_AUC: 0.5819\n",
      "Epoch 62/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0098 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 6.5534 - val_Accuracy: 0.4660 - val_AUC: 0.6303\n",
      "Epoch 63/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0093 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 6.6219 - val_Accuracy: 0.4761 - val_AUC: 0.6336\n",
      "Epoch 64/70\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0087 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 6.1384 - val_Accuracy: 0.4937 - val_AUC: 0.6388\n",
      "Epoch 65/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0105 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 5.6554 - val_Accuracy: 0.5491 - val_AUC: 0.6595\n",
      "Epoch 66/70\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0085 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.3804 - val_Accuracy: 0.5793 - val_AUC: 0.6632\n",
      "Epoch 67/70\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0093 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 4.6547 - val_Accuracy: 0.5617 - val_AUC: 0.6568\n",
      "Epoch 68/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0107 - Accuracy: 0.9968 - AUC: 0.9997 - val_loss: 9.1974 - val_Accuracy: 0.3401 - val_AUC: 0.5446\n",
      "Epoch 69/70\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0087 - Accuracy: 0.9962 - AUC: 1.0000 - val_loss: 8.4411 - val_Accuracy: 0.3401 - val_AUC: 0.5540\n",
      "Epoch 70/70\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0107 - Accuracy: 0.9956 - AUC: 1.0000 - val_loss: 8.8741 - val_Accuracy: 0.3350 - val_AUC: 0.5329\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_encode,y_train_bin,batch_size=40,epochs=70,verbose=1,validation_data=(X_val_encode,y_val_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6114c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed3c3182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9802834e-01, 1.8362774e-03, 1.3542578e-04],\n",
       "       [2.6026403e-04, 9.9969471e-01, 4.5032444e-05],\n",
       "       [9.6806179e-04, 4.8854470e-04, 9.9854338e-01],\n",
       "       ...,\n",
       "       [6.6700229e-11, 9.2291325e-10, 1.0000000e+00],\n",
       "       [1.0278149e-08, 1.0000000e+00, 7.3419137e-10],\n",
       "       [4.8591992e-11, 7.2220935e-10, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ef10b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 1, 1, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 0,\n",
       "       2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 2, 1, 1, 0, 2, 2, 0, 0, 0, 1, 2, 2,\n",
       "       0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       2, 1, 2, 1, 2, 2, 0, 1, 2, 1, 2, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2,\n",
       "       0, 0, 1, 0, 2, 2, 2, 1, 2, 0, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2,\n",
       "       1, 1, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0,\n",
       "       2, 1, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 0,\n",
       "       2, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0,\n",
       "       2, 2, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1,\n",
       "       2, 0, 2, 0, 1, 0, 2, 0, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 0, 2, 2,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       0, 0, 2, 2, 2, 1, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 2, 0, 2,\n",
       "       0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1,\n",
       "       2, 0, 0, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2,\n",
       "       1, 1, 1, 2, 1, 2, 0, 1, 0, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 2, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1,\n",
       "       2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 1, 2, 1, 0,\n",
       "       1, 1, 2, 0, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1,\n",
       "       1, 0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc39887c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "782ab0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdfc2c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 1, 1, 0,\n",
       "       1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 0,\n",
       "       2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 2, 1, 1, 0, 2, 2, 0, 0, 1, 1, 2, 2,\n",
       "       0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2,\n",
       "       0, 0, 1, 0, 2, 2, 2, 1, 2, 0, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2,\n",
       "       1, 1, 2, 2, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0,\n",
       "       2, 1, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 0,\n",
       "       2, 1, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0,\n",
       "       2, 2, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1,\n",
       "       2, 0, 2, 0, 1, 0, 2, 0, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 0, 2, 2,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 2, 0, 2,\n",
       "       0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1,\n",
       "       2, 0, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2,\n",
       "       1, 1, 1, 2, 1, 2, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 2, 1,\n",
       "       2, 0, 2, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1,\n",
       "       2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 0,\n",
       "       1, 1, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1,\n",
       "       1, 0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d9b94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prednew=label_binarize(y_pred,classes=np.unique(y_pred))\n",
    "classes=np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e805b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prednew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05dde01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51c462d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       167\n",
      "           1       0.93      0.99      0.96       186\n",
      "           2       0.99      0.99      0.99       143\n",
      "\n",
      "    accuracy                           0.97       496\n",
      "   macro avg       0.97      0.97      0.97       496\n",
      "weighted avg       0.97      0.97      0.97       496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fdd1670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0080 - Accuracy: 0.9956 - AUC: 1.0000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 8.8741 - Accuracy: 0.3350 - AUC: 0.5329\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1405 - Accuracy: 0.9698 - AUC: 0.9944\n",
      "Training Accuracy: 99.56%\n",
      "Validation Accuracy: 33.50%\n",
      "Testing Accuracy: 96.98%\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(X_train_encode, y_train_bin)\n",
    "val_scores = model.evaluate(X_val_encode, y_val_bin)\n",
    "test_scores = model.evaluate(X_test_encode, y_test_bin)\n",
    "\n",
    "print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
    "print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477849f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
