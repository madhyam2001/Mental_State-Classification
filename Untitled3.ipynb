{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc1420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca111dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0       33.965587  ...    0.000230    0.000351    0.000547    0.000381   \n",
       "1       40.893307  ...    0.001671    0.000740    0.001122    0.000521   \n",
       "2       30.692883  ...    0.000748    0.000569    0.000327    0.000197   \n",
       "3       20.777411  ...    0.000990    0.005644    0.006891    0.010546   \n",
       "4       32.658163  ...    0.001659    0.014379    0.014492    0.002949   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.000350    0.000453    0.000442    0.000325    0.000209    2.0  \n",
       "1    0.000624    0.000439    0.001249    0.000727    0.000801    2.0  \n",
       "2    0.000833    0.000909    0.000699    0.001165    0.000616    2.0  \n",
       "3    0.009583    0.011158    0.008853    0.004551    0.002287    1.0  \n",
       "4    0.004575    0.008305    0.007202    0.006957    0.009836    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472d63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lag1_mean_0           False\n",
       "lag1_mean_1           False\n",
       "lag1_mean_2           False\n",
       "lag1_mean_3           False\n",
       "lag1_mean_d_h2h1_0    False\n",
       "                      ...  \n",
       "freq_720_3            False\n",
       "freq_730_3            False\n",
       "freq_740_3            False\n",
       "freq_750_3            False\n",
       "Label                 False\n",
       "Length: 989, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecde7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.584351</td>\n",
       "      <td>27.060411</td>\n",
       "      <td>20.452931</td>\n",
       "      <td>11.526044</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.554037</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>23.271148</td>\n",
       "      <td>26.809551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>1.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.543938</td>\n",
       "      <td>24.252348</td>\n",
       "      <td>72.104439</td>\n",
       "      <td>19.196870</td>\n",
       "      <td>13.382998</td>\n",
       "      <td>39.383221</td>\n",
       "      <td>97.200697</td>\n",
       "      <td>14.461716</td>\n",
       "      <td>17.639164</td>\n",
       "      <td>36.255490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.815743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.224945</td>\n",
       "      <td>-369.150109</td>\n",
       "      <td>-579.490660</td>\n",
       "      <td>-251.495367</td>\n",
       "      <td>-75.143730</td>\n",
       "      <td>-728.743981</td>\n",
       "      <td>-1048.773622</td>\n",
       "      <td>-96.231800</td>\n",
       "      <td>-351.810178</td>\n",
       "      <td>-800.320690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.732076</td>\n",
       "      <td>21.328936</td>\n",
       "      <td>17.124174</td>\n",
       "      <td>6.541236</td>\n",
       "      <td>-4.647636</td>\n",
       "      <td>-3.342428</td>\n",
       "      <td>-6.773096</td>\n",
       "      <td>-4.498267</td>\n",
       "      <td>17.020349</td>\n",
       "      <td>20.684966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.553828</td>\n",
       "      <td>27.574535</td>\n",
       "      <td>25.217098</td>\n",
       "      <td>15.144375</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>-0.180041</td>\n",
       "      <td>23.761987</td>\n",
       "      <td>27.442672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.759551</td>\n",
       "      <td>32.247539</td>\n",
       "      <td>30.746496</td>\n",
       "      <td>20.589852</td>\n",
       "      <td>3.965898</td>\n",
       "      <td>3.594742</td>\n",
       "      <td>7.305102</td>\n",
       "      <td>4.146319</td>\n",
       "      <td>29.574478</td>\n",
       "      <td>32.720855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.313766</td>\n",
       "      <td>408.180215</td>\n",
       "      <td>591.014113</td>\n",
       "      <td>69.694520</td>\n",
       "      <td>104.963158</td>\n",
       "      <td>512.648208</td>\n",
       "      <td>896.171353</td>\n",
       "      <td>172.660240</td>\n",
       "      <td>116.412065</td>\n",
       "      <td>539.925670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>0.053044</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>0.071582</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000         2479.000000   \n",
       "mean     23.584351    27.060411    20.452931    11.526044            0.014449   \n",
       "std      10.543938    24.252348    72.104439    19.196870           13.382998   \n",
       "min     -35.224945  -369.150109  -579.490660  -251.495367          -75.143730   \n",
       "25%      18.732076    21.328936    17.124174     6.541236           -4.647636   \n",
       "50%      23.553828    27.574535    25.217098    15.144375           -0.140909   \n",
       "75%      27.759551    32.247539    30.746496    20.589852            3.965898   \n",
       "max      92.313766   408.180215   591.014113    69.694520          104.963158   \n",
       "\n",
       "       lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "count         2479.000000         2479.000000         2479.000000   \n",
       "mean             0.003397            0.554037            0.103880   \n",
       "std             39.383221           97.200697           14.461716   \n",
       "min           -728.743981        -1048.773622          -96.231800   \n",
       "25%             -3.342428           -6.773096           -4.498267   \n",
       "50%              0.180963            0.144378           -0.180041   \n",
       "75%              3.594742            7.305102            4.146319   \n",
       "max            512.648208          896.171353          172.660240   \n",
       "\n",
       "       lag1_mean_q1_0  lag1_mean_q1_1  ...   freq_669_3   freq_679_3  \\\n",
       "count     2479.000000     2479.000000  ...  2479.000000  2479.000000   \n",
       "mean        23.271148       26.809551  ...     0.008141     0.008063   \n",
       "std         17.639164       36.255490  ...     0.007653     0.007572   \n",
       "min       -351.810178     -800.320690  ...     0.000036     0.000024   \n",
       "25%         17.020349       20.684966  ...     0.002192     0.002169   \n",
       "50%         23.761987       27.442672  ...     0.006239     0.006029   \n",
       "75%         29.574478       32.720855  ...     0.011497     0.011610   \n",
       "max        116.412065      539.925670  ...     0.069699     0.058378   \n",
       "\n",
       "        freq_689_3   freq_699_3   freq_709_3   freq_720_3   freq_730_3  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000  2479.000000   \n",
       "mean      0.007784     0.007679     0.007413     0.007998     0.007449   \n",
       "std       0.007458     0.007276     0.007060     0.007547     0.006937   \n",
       "min       0.000018     0.000027     0.000052     0.000041     0.000008   \n",
       "25%       0.002108     0.002151     0.001930     0.002034     0.001985   \n",
       "50%       0.005735     0.005632     0.005532     0.006005     0.005717   \n",
       "75%       0.010986     0.011150     0.010645     0.011406     0.010768   \n",
       "max       0.086914     0.065296     0.053044     0.054104     0.060196   \n",
       "\n",
       "        freq_740_3   freq_750_3        Label  \n",
       "count  2479.000000  2479.000000  2479.000000  \n",
       "mean      0.007307     0.007382     1.004437  \n",
       "std       0.007379     0.007276     0.815743  \n",
       "min       0.000036     0.000048     0.000000  \n",
       "25%       0.002042     0.001964     0.000000  \n",
       "50%       0.005300     0.005315     1.000000  \n",
       "75%       0.010208     0.010330     2.000000  \n",
       "max       0.134037     0.071582     2.000000  \n",
       "\n",
       "[8 rows x 989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31849d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 988)\n",
      "(2479,)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['Label'],axis=1)\n",
    "y=df['Label'].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aa7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b84a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983, 988)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e69848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmadhyam_2001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b839e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "# mi_score = MIC(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ee1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score = pd.Series(mi_score, index=x.columns)\n",
    "# mi_score = (mi_score*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1018b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features1 = mi_score[:-364].index # 2184. 10% MI-score\n",
    "# top_features2 = mi_score[:-552].index # 1996. 20% MI-score\n",
    "# top_features3 = mi_score[:-1095].index # 1453. 30% MI-score\n",
    "# top_features4 = mi_score[:-1960].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dcf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d111a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters1, filters2, kernel_size1, kernel_size2, dropout1, dropout2):\n",
    "\n",
    "  model=models.Sequential()\n",
    "  model.add(layers.Conv1D(filters1, kernel_size1, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout1))\n",
    "  model.add(layers.ReLU())\n",
    "\n",
    "  model.add(layers.Conv1D(filters2, kernel_size2,activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "  model.add(layers.ReLU())\n",
    "#   model.add(layers.Flatten())\n",
    "    \n",
    "  model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPooling1D())\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "196d88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ASUS\\Documents\\Mental_State_Classification\\wandb\\run-20220708_172741-bcff1p6h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/bcff1p6h\" target=\"_blank\">smooth-sponge-13</a></strong> to <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 984, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 984, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 492, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 492, 64)           0         \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 492, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 488, 64)           20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 488, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 244, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 244, 64)           0         \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 244, 64)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 240, 32)           10272     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 240, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 120, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 120, 32)           0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 120, 32)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 11523     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,363\n",
      "Trainable params: 43,043\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='eeg-mental_state-classification',\n",
    "                 config={  \n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 30,\n",
    "                     \"batch_size\": 28,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"filters1\": 64,\n",
    "                     \"filters2\": 64,\n",
    "                     \"kernel_size1\": 5,\n",
    "                     \"kernel_size2\" : 5,\n",
    "                     \"dropout1\": 0.5,\n",
    "                     \"dropout2\": 0.5\n",
    "                 })\n",
    "config = wandb.config\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model(config.filters1, config.filters2, config.kernel_size1, config.kernel_size2, config.dropout1, config.dropout2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78d680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5219: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 7s 95ms/step - loss: 1.1177 - accuracy: 0.5205 - val_loss: 1.0552 - val_accuracy: 0.6935 - _timestamp: 1657281487.0000 - _runtime: 26.0000\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.9885 - accuracy: 0.5965 - val_loss: 0.9423 - val_accuracy: 0.5988 - _timestamp: 1657281492.0000 - _runtime: 31.0000\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.9410 - accuracy: 0.6093 - val_loss: 0.9344 - val_accuracy: 0.5524 - _timestamp: 1657281497.0000 - _runtime: 36.0000\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 5s 95ms/step - loss: 0.8818 - accuracy: 0.6032 - val_loss: 0.9198 - val_accuracy: 0.5403 - _timestamp: 1657281502.0000 - _runtime: 41.0000\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.9525 - accuracy: 0.5931 - val_loss: 0.9575 - val_accuracy: 0.5625 - _timestamp: 1657281507.0000 - _runtime: 46.0000\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.9383 - accuracy: 0.6174 - val_loss: 1.0075 - val_accuracy: 0.6210 - _timestamp: 1657281512.0000 - _runtime: 51.0000\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.8930 - accuracy: 0.6026 - val_loss: 0.9383 - val_accuracy: 0.5887 - _timestamp: 1657281517.0000 - _runtime: 56.0000\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.8926 - accuracy: 0.5952 - val_loss: 0.8760 - val_accuracy: 0.5645 - _timestamp: 1657281522.0000 - _runtime: 61.0000\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 5s 94ms/step - loss: 0.8982 - accuracy: 0.5992 - val_loss: 0.9277 - val_accuracy: 0.5685 - _timestamp: 1657281527.0000 - _runtime: 66.0000\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.8693 - accuracy: 0.6133 - val_loss: 0.8896 - val_accuracy: 0.4919 - _timestamp: 1657281532.0000 - _runtime: 71.0000\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.8632 - accuracy: 0.6079 - val_loss: 0.8958 - val_accuracy: 0.5222 - _timestamp: 1657281537.0000 - _runtime: 76.0000\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.8249 - accuracy: 0.6167 - val_loss: 0.8774 - val_accuracy: 0.5161 - _timestamp: 1657281542.0000 - _runtime: 81.0000\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.8117 - accuracy: 0.6308 - val_loss: 0.8337 - val_accuracy: 0.5685 - _timestamp: 1657281547.0000 - _runtime: 86.0000\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.8291 - accuracy: 0.6456 - val_loss: 0.8301 - val_accuracy: 0.5101 - _timestamp: 1657281552.0000 - _runtime: 91.0000\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.8039 - accuracy: 0.6550 - val_loss: 0.7693 - val_accuracy: 0.6492 - _timestamp: 1657281557.0000 - _runtime: 96.0000\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.7659 - accuracy: 0.6389 - val_loss: 0.8141 - val_accuracy: 0.5645 - _timestamp: 1657281562.0000 - _runtime: 101.0000\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.7364 - accuracy: 0.6826 - val_loss: 0.7979 - val_accuracy: 0.5383 - _timestamp: 1657281567.0000 - _runtime: 106.0000\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.7217 - accuracy: 0.6785 - val_loss: 0.7281 - val_accuracy: 0.6915 - _timestamp: 1657281572.0000 - _runtime: 111.0000\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.7216 - accuracy: 0.6933 - val_loss: 0.7636 - val_accuracy: 0.5907 - _timestamp: 1657281577.0000 - _runtime: 116.0000\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.6801 - accuracy: 0.7021 - val_loss: 0.7191 - val_accuracy: 0.7722 - _timestamp: 1657281581.0000 - _runtime: 120.0000\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.7410 - accuracy: 0.7001 - val_loss: 0.6999 - val_accuracy: 0.6815 - _timestamp: 1657281586.0000 - _runtime: 125.0000\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.6731 - accuracy: 0.7081 - val_loss: 0.6586 - val_accuracy: 0.7157 - _timestamp: 1657281591.0000 - _runtime: 130.0000\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.6648 - accuracy: 0.7216 - val_loss: 0.6241 - val_accuracy: 0.7460 - _timestamp: 1657281596.0000 - _runtime: 135.0000\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.6485 - accuracy: 0.7283 - val_loss: 0.6476 - val_accuracy: 0.7077 - _timestamp: 1657281601.0000 - _runtime: 140.0000\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 0.6500 - accuracy: 0.7162 - val_loss: 0.6919 - val_accuracy: 0.6694 - _timestamp: 1657281606.0000 - _runtime: 145.0000\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.6313 - accuracy: 0.7229 - val_loss: 0.5686 - val_accuracy: 0.8044 - _timestamp: 1657281611.0000 - _runtime: 150.0000\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.6379 - accuracy: 0.7276 - val_loss: 0.5896 - val_accuracy: 0.7742 - _timestamp: 1657281617.0000 - _runtime: 156.0000\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.6039 - accuracy: 0.7404 - val_loss: 0.6264 - val_accuracy: 0.7137 - _timestamp: 1657281622.0000 - _runtime: 161.0000\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.6077 - accuracy: 0.7458 - val_loss: 0.6009 - val_accuracy: 0.7278 - _timestamp: 1657281628.0000 - _runtime: 167.0000\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.5680 - accuracy: 0.7619 - val_loss: 0.6427 - val_accuracy: 0.7077 - _timestamp: 1657281633.0000 - _runtime: 172.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          epochs=config.epochs, \n",
    "          batch_size=config.batch_size,\n",
    "          validation_split=0.25,\n",
    "          shuffle=False,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f17d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6121 - accuracy: 0.6754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.574 MB of 0.574 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▃▄▃▃▄▃▃▃▄▄▄▄▅▅▄▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▆▅▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▃▂▂▂▂▂▂▁▂▁</td></tr><tr><td>val_accuracy</td><td>▆▃▂▂▃▄▃▃▃▁▂▂▃▁▅▃▂▅▃▇▅▆▇▆▅█▇▆▆▆</td></tr><tr><td>val_loss</td><td>█▆▆▆▇▇▆▅▆▆▆▅▅▅▄▅▄▃▄▃▃▂▂▂▃▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.01293</td></tr><tr><td>Test Accuracy</td><td>0.6754</td></tr><tr><td>accuracy</td><td>0.76194</td></tr><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_loss</td><td>0.56856</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.56798</td></tr><tr><td>val_accuracy</td><td>0.70766</td></tr><tr><td>val_loss</td><td>0.64268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-sponge-13</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/bcff1p6h\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/bcff1p6h</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220708_172741-bcff1p6h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "wandb.log({'Test Accuracy': accuracy})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4522f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
