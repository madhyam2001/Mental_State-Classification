{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc1420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca111dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0       33.965587  ...    0.000230    0.000351    0.000547    0.000381   \n",
       "1       40.893307  ...    0.001671    0.000740    0.001122    0.000521   \n",
       "2       30.692883  ...    0.000748    0.000569    0.000327    0.000197   \n",
       "3       20.777411  ...    0.000990    0.005644    0.006891    0.010546   \n",
       "4       32.658163  ...    0.001659    0.014379    0.014492    0.002949   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.000350    0.000453    0.000442    0.000325    0.000209    2.0  \n",
       "1    0.000624    0.000439    0.001249    0.000727    0.000801    2.0  \n",
       "2    0.000833    0.000909    0.000699    0.001165    0.000616    2.0  \n",
       "3    0.009583    0.011158    0.008853    0.004551    0.002287    1.0  \n",
       "4    0.004575    0.008305    0.007202    0.006957    0.009836    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472d63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lag1_mean_0           False\n",
       "lag1_mean_1           False\n",
       "lag1_mean_2           False\n",
       "lag1_mean_3           False\n",
       "lag1_mean_d_h2h1_0    False\n",
       "                      ...  \n",
       "freq_720_3            False\n",
       "freq_730_3            False\n",
       "freq_740_3            False\n",
       "freq_750_3            False\n",
       "Label                 False\n",
       "Length: 989, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecde7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.584351</td>\n",
       "      <td>27.060411</td>\n",
       "      <td>20.452931</td>\n",
       "      <td>11.526044</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.554037</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>23.271148</td>\n",
       "      <td>26.809551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>1.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.543938</td>\n",
       "      <td>24.252348</td>\n",
       "      <td>72.104439</td>\n",
       "      <td>19.196870</td>\n",
       "      <td>13.382998</td>\n",
       "      <td>39.383221</td>\n",
       "      <td>97.200697</td>\n",
       "      <td>14.461716</td>\n",
       "      <td>17.639164</td>\n",
       "      <td>36.255490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.815743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.224945</td>\n",
       "      <td>-369.150109</td>\n",
       "      <td>-579.490660</td>\n",
       "      <td>-251.495367</td>\n",
       "      <td>-75.143730</td>\n",
       "      <td>-728.743981</td>\n",
       "      <td>-1048.773622</td>\n",
       "      <td>-96.231800</td>\n",
       "      <td>-351.810178</td>\n",
       "      <td>-800.320690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.732076</td>\n",
       "      <td>21.328936</td>\n",
       "      <td>17.124174</td>\n",
       "      <td>6.541236</td>\n",
       "      <td>-4.647636</td>\n",
       "      <td>-3.342428</td>\n",
       "      <td>-6.773096</td>\n",
       "      <td>-4.498267</td>\n",
       "      <td>17.020349</td>\n",
       "      <td>20.684966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.553828</td>\n",
       "      <td>27.574535</td>\n",
       "      <td>25.217098</td>\n",
       "      <td>15.144375</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>-0.180041</td>\n",
       "      <td>23.761987</td>\n",
       "      <td>27.442672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.759551</td>\n",
       "      <td>32.247539</td>\n",
       "      <td>30.746496</td>\n",
       "      <td>20.589852</td>\n",
       "      <td>3.965898</td>\n",
       "      <td>3.594742</td>\n",
       "      <td>7.305102</td>\n",
       "      <td>4.146319</td>\n",
       "      <td>29.574478</td>\n",
       "      <td>32.720855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.313766</td>\n",
       "      <td>408.180215</td>\n",
       "      <td>591.014113</td>\n",
       "      <td>69.694520</td>\n",
       "      <td>104.963158</td>\n",
       "      <td>512.648208</td>\n",
       "      <td>896.171353</td>\n",
       "      <td>172.660240</td>\n",
       "      <td>116.412065</td>\n",
       "      <td>539.925670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>0.053044</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>0.071582</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000         2479.000000   \n",
       "mean     23.584351    27.060411    20.452931    11.526044            0.014449   \n",
       "std      10.543938    24.252348    72.104439    19.196870           13.382998   \n",
       "min     -35.224945  -369.150109  -579.490660  -251.495367          -75.143730   \n",
       "25%      18.732076    21.328936    17.124174     6.541236           -4.647636   \n",
       "50%      23.553828    27.574535    25.217098    15.144375           -0.140909   \n",
       "75%      27.759551    32.247539    30.746496    20.589852            3.965898   \n",
       "max      92.313766   408.180215   591.014113    69.694520          104.963158   \n",
       "\n",
       "       lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "count         2479.000000         2479.000000         2479.000000   \n",
       "mean             0.003397            0.554037            0.103880   \n",
       "std             39.383221           97.200697           14.461716   \n",
       "min           -728.743981        -1048.773622          -96.231800   \n",
       "25%             -3.342428           -6.773096           -4.498267   \n",
       "50%              0.180963            0.144378           -0.180041   \n",
       "75%              3.594742            7.305102            4.146319   \n",
       "max            512.648208          896.171353          172.660240   \n",
       "\n",
       "       lag1_mean_q1_0  lag1_mean_q1_1  ...   freq_669_3   freq_679_3  \\\n",
       "count     2479.000000     2479.000000  ...  2479.000000  2479.000000   \n",
       "mean        23.271148       26.809551  ...     0.008141     0.008063   \n",
       "std         17.639164       36.255490  ...     0.007653     0.007572   \n",
       "min       -351.810178     -800.320690  ...     0.000036     0.000024   \n",
       "25%         17.020349       20.684966  ...     0.002192     0.002169   \n",
       "50%         23.761987       27.442672  ...     0.006239     0.006029   \n",
       "75%         29.574478       32.720855  ...     0.011497     0.011610   \n",
       "max        116.412065      539.925670  ...     0.069699     0.058378   \n",
       "\n",
       "        freq_689_3   freq_699_3   freq_709_3   freq_720_3   freq_730_3  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000  2479.000000   \n",
       "mean      0.007784     0.007679     0.007413     0.007998     0.007449   \n",
       "std       0.007458     0.007276     0.007060     0.007547     0.006937   \n",
       "min       0.000018     0.000027     0.000052     0.000041     0.000008   \n",
       "25%       0.002108     0.002151     0.001930     0.002034     0.001985   \n",
       "50%       0.005735     0.005632     0.005532     0.006005     0.005717   \n",
       "75%       0.010986     0.011150     0.010645     0.011406     0.010768   \n",
       "max       0.086914     0.065296     0.053044     0.054104     0.060196   \n",
       "\n",
       "        freq_740_3   freq_750_3        Label  \n",
       "count  2479.000000  2479.000000  2479.000000  \n",
       "mean      0.007307     0.007382     1.004437  \n",
       "std       0.007379     0.007276     0.815743  \n",
       "min       0.000036     0.000048     0.000000  \n",
       "25%       0.002042     0.001964     0.000000  \n",
       "50%       0.005300     0.005315     1.000000  \n",
       "75%       0.010208     0.010330     2.000000  \n",
       "max       0.134037     0.071582     2.000000  \n",
       "\n",
       "[8 rows x 989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31849d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 988)\n",
      "(2479,)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['Label'],axis=1)\n",
    "y=df['Label'].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aa7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b84a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983, 988)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e69848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmadhyam_2001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b839e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "# mi_score = MIC(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ee1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score = pd.Series(mi_score, index=x.columns)\n",
    "# mi_score = (mi_score*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1018b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features1 = mi_score[:-364].index # 2184. 10% MI-score\n",
    "# top_features2 = mi_score[:-552].index # 1996. 20% MI-score\n",
    "# top_features3 = mi_score[:-1095].index # 1453. 30% MI-score\n",
    "# top_features4 = mi_score[:-1960].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6dcf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d111a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters1, filters2, kernel_size1, kernel_size2, dropout1, dropout2):\n",
    "\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv1D(filters1, kernel_size1, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout1))\n",
    "\n",
    "  model.add(layers.Conv1D(filters2, kernel_size2))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "196d88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ASUS\\Documents\\Mental_State_Classification\\wandb\\run-20220702_165536-1t46t55g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/1t46t55g\" target=\"_blank\">dulcet-flower-6</a></strong> to <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 984, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 984, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 984, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 492, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 492, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 488, 64)           20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 488, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 488, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 244, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 244, 64)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15616)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 46851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,291\n",
      "Trainable params: 68,035\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='eeg-mental_state-classification',\n",
    "                 config={  \n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 30,\n",
    "                     \"batch_size\": 28,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"filters1\": 64,\n",
    "                     \"filters2\": 64,\n",
    "                     \"kernel_size1\": 5,\n",
    "                     \"kernel_size2\" : 5,\n",
    "                     \"dropout1\": 0.5,\n",
    "                     \"dropout2\": 0.5\n",
    "                 })\n",
    "config = wandb.config\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model(config.filters1, config.filters2, config.kernel_size1, config.kernel_size2, config.dropout1, config.dropout2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cccecb2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12632/2970753911.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "files.download('model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78d680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 1.0450 - accuracy: 0.5925 - val_loss: 1.3181 - val_accuracy: 0.7198 - _timestamp: 1656761254.0000 - _runtime: 118.0000\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 0.9674 - accuracy: 0.6214 - val_loss: 1.0636 - val_accuracy: 0.6996 - _timestamp: 1656761258.0000 - _runtime: 122.0000\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 0.8927 - accuracy: 0.6167 - val_loss: 0.8629 - val_accuracy: 0.5827 - _timestamp: 1656761263.0000 - _runtime: 127.0000\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 0.8327 - accuracy: 0.6301 - val_loss: 0.9023 - val_accuracy: 0.6573 - _timestamp: 1656761267.0000 - _runtime: 131.0000\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 4s 82ms/step - loss: 0.8562 - accuracy: 0.6126 - val_loss: 1.0837 - val_accuracy: 0.6270 - _timestamp: 1656761272.0000 - _runtime: 136.0000\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 4s 82ms/step - loss: 0.8642 - accuracy: 0.6429 - val_loss: 0.9359 - val_accuracy: 0.6109 - _timestamp: 1656761276.0000 - _runtime: 140.0000\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.8018 - accuracy: 0.6281 - val_loss: 0.9220 - val_accuracy: 0.6371 - _timestamp: 1656761281.0000 - _runtime: 145.0000\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.7290 - accuracy: 0.6651 - val_loss: 0.8569 - val_accuracy: 0.6290 - _timestamp: 1656761285.0000 - _runtime: 149.0000\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.7687 - accuracy: 0.6651 - val_loss: 0.8953 - val_accuracy: 0.6996 - _timestamp: 1656761290.0000 - _runtime: 154.0000\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.7541 - accuracy: 0.6752 - val_loss: 0.8623 - val_accuracy: 0.7238 - _timestamp: 1656761294.0000 - _runtime: 158.0000\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.7916 - accuracy: 0.6409 - val_loss: 0.9522 - val_accuracy: 0.6593 - _timestamp: 1656761299.0000 - _runtime: 163.0000\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.7412 - accuracy: 0.6812 - val_loss: 0.7573 - val_accuracy: 0.5323 - _timestamp: 1656761303.0000 - _runtime: 167.0000\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.7729 - accuracy: 0.6705 - val_loss: 0.6834 - val_accuracy: 0.6472 - _timestamp: 1656761308.0000 - _runtime: 172.0000\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.7390 - accuracy: 0.6967 - val_loss: 0.6754 - val_accuracy: 0.6875 - _timestamp: 1656761312.0000 - _runtime: 176.0000\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.7774 - accuracy: 0.6711 - val_loss: 0.7452 - val_accuracy: 0.6371 - _timestamp: 1656761317.0000 - _runtime: 181.0000\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 5s 83ms/step - loss: 0.6803 - accuracy: 0.7095 - val_loss: 0.7326 - val_accuracy: 0.7218 - _timestamp: 1656761321.0000 - _runtime: 185.0000\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 5s 86ms/step - loss: 0.6955 - accuracy: 0.7128 - val_loss: 0.7322 - val_accuracy: 0.7359 - _timestamp: 1656761326.0000 - _runtime: 190.0000\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 5s 83ms/step - loss: 0.6996 - accuracy: 0.7115 - val_loss: 0.7545 - val_accuracy: 0.7440 - _timestamp: 1656761331.0000 - _runtime: 195.0000\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.6528 - accuracy: 0.7095 - val_loss: 0.6562 - val_accuracy: 0.7077 - _timestamp: 1656761335.0000 - _runtime: 199.0000\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.6070 - accuracy: 0.7276 - val_loss: 0.7225 - val_accuracy: 0.7641 - _timestamp: 1656761340.0000 - _runtime: 204.0000\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 5s 96ms/step - loss: 0.6335 - accuracy: 0.7337 - val_loss: 0.6236 - val_accuracy: 0.7500 - _timestamp: 1656761345.0000 - _runtime: 209.0000\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.5634 - accuracy: 0.7478 - val_loss: 0.6547 - val_accuracy: 0.7702 - _timestamp: 1656761349.0000 - _runtime: 213.0000\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 5s 85ms/step - loss: 0.6201 - accuracy: 0.7478 - val_loss: 0.6079 - val_accuracy: 0.6996 - _timestamp: 1656761354.0000 - _runtime: 218.0000\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.6075 - accuracy: 0.7102 - val_loss: 0.5796 - val_accuracy: 0.7722 - _timestamp: 1656761358.0000 - _runtime: 222.0000\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 4s 83ms/step - loss: 0.6056 - accuracy: 0.7357 - val_loss: 0.5760 - val_accuracy: 0.7419 - _timestamp: 1656761363.0000 - _runtime: 227.0000\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 5s 83ms/step - loss: 0.5847 - accuracy: 0.7498 - val_loss: 0.8011 - val_accuracy: 0.6895 - _timestamp: 1656761368.0000 - _runtime: 232.0000\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 5s 83ms/step - loss: 0.5782 - accuracy: 0.7438 - val_loss: 0.6768 - val_accuracy: 0.7500 - _timestamp: 1656761372.0000 - _runtime: 236.0000\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.5979 - accuracy: 0.7579 - val_loss: 0.5739 - val_accuracy: 0.7379 - _timestamp: 1656761377.0000 - _runtime: 241.0000\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 5s 87ms/step - loss: 0.5654 - accuracy: 0.7431 - val_loss: 0.6692 - val_accuracy: 0.7460 - _timestamp: 1656761381.0000 - _runtime: 245.0000\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.5596 - accuracy: 0.7512 - val_loss: 0.5811 - val_accuracy: 0.7621 - _timestamp: 1656761386.0000 - _runtime: 250.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          epochs=config.epochs, \n",
    "          batch_size=config.batch_size,\n",
    "          validation_split=0.25,\n",
    "          shuffle=True,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f17d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5866 - accuracy: 0.7359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.838 MB of 0.838 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▂▂▃▂▃▃▄▄▅▃▅▄▅▄▆▆▆▆▇▇██▆▇█▇█▇█</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▅▅▅▄▃▄▄▄▄▄▄▄▃▃▃▂▂▂▁▂▂▂▁▁▂▁▁</td></tr><tr><td>val_accuracy</td><td>▆▆▂▅▄▃▄▄▆▇▅▁▄▆▄▇▇▇▆█▇█▆█▇▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▄▄▆▄▄▄▄▄▅▃▂▂▃▂▂▃▂▂▁▂▁▁▁▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.73589</td></tr><tr><td>accuracy</td><td>0.75118</td></tr><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_loss</td><td>0.57393</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.55956</td></tr><tr><td>val_accuracy</td><td>0.7621</td></tr><tr><td>val_loss</td><td>0.58113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dulcet-flower-6</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/1t46t55g\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/1t46t55g</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220702_165536-1t46t55g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "wandb.log({'Test Accuracy': accuracy})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4522f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
