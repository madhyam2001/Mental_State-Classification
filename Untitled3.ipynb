{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc1420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca111dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0       33.965587  ...    0.000230    0.000351    0.000547    0.000381   \n",
       "1       40.893307  ...    0.001671    0.000740    0.001122    0.000521   \n",
       "2       30.692883  ...    0.000748    0.000569    0.000327    0.000197   \n",
       "3       20.777411  ...    0.000990    0.005644    0.006891    0.010546   \n",
       "4       32.658163  ...    0.001659    0.014379    0.014492    0.002949   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.000350    0.000453    0.000442    0.000325    0.000209    2.0  \n",
       "1    0.000624    0.000439    0.001249    0.000727    0.000801    2.0  \n",
       "2    0.000833    0.000909    0.000699    0.001165    0.000616    2.0  \n",
       "3    0.009583    0.011158    0.008853    0.004551    0.002287    1.0  \n",
       "4    0.004575    0.008305    0.007202    0.006957    0.009836    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472d63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lag1_mean_0           False\n",
       "lag1_mean_1           False\n",
       "lag1_mean_2           False\n",
       "lag1_mean_3           False\n",
       "lag1_mean_d_h2h1_0    False\n",
       "                      ...  \n",
       "freq_720_3            False\n",
       "freq_730_3            False\n",
       "freq_740_3            False\n",
       "freq_750_3            False\n",
       "Label                 False\n",
       "Length: 989, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecde7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.584351</td>\n",
       "      <td>27.060411</td>\n",
       "      <td>20.452931</td>\n",
       "      <td>11.526044</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.554037</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>23.271148</td>\n",
       "      <td>26.809551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>1.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.543938</td>\n",
       "      <td>24.252348</td>\n",
       "      <td>72.104439</td>\n",
       "      <td>19.196870</td>\n",
       "      <td>13.382998</td>\n",
       "      <td>39.383221</td>\n",
       "      <td>97.200697</td>\n",
       "      <td>14.461716</td>\n",
       "      <td>17.639164</td>\n",
       "      <td>36.255490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.815743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.224945</td>\n",
       "      <td>-369.150109</td>\n",
       "      <td>-579.490660</td>\n",
       "      <td>-251.495367</td>\n",
       "      <td>-75.143730</td>\n",
       "      <td>-728.743981</td>\n",
       "      <td>-1048.773622</td>\n",
       "      <td>-96.231800</td>\n",
       "      <td>-351.810178</td>\n",
       "      <td>-800.320690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.732076</td>\n",
       "      <td>21.328936</td>\n",
       "      <td>17.124174</td>\n",
       "      <td>6.541236</td>\n",
       "      <td>-4.647636</td>\n",
       "      <td>-3.342428</td>\n",
       "      <td>-6.773096</td>\n",
       "      <td>-4.498267</td>\n",
       "      <td>17.020349</td>\n",
       "      <td>20.684966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.553828</td>\n",
       "      <td>27.574535</td>\n",
       "      <td>25.217098</td>\n",
       "      <td>15.144375</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>-0.180041</td>\n",
       "      <td>23.761987</td>\n",
       "      <td>27.442672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.759551</td>\n",
       "      <td>32.247539</td>\n",
       "      <td>30.746496</td>\n",
       "      <td>20.589852</td>\n",
       "      <td>3.965898</td>\n",
       "      <td>3.594742</td>\n",
       "      <td>7.305102</td>\n",
       "      <td>4.146319</td>\n",
       "      <td>29.574478</td>\n",
       "      <td>32.720855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.313766</td>\n",
       "      <td>408.180215</td>\n",
       "      <td>591.014113</td>\n",
       "      <td>69.694520</td>\n",
       "      <td>104.963158</td>\n",
       "      <td>512.648208</td>\n",
       "      <td>896.171353</td>\n",
       "      <td>172.660240</td>\n",
       "      <td>116.412065</td>\n",
       "      <td>539.925670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>0.053044</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>0.071582</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000         2479.000000   \n",
       "mean     23.584351    27.060411    20.452931    11.526044            0.014449   \n",
       "std      10.543938    24.252348    72.104439    19.196870           13.382998   \n",
       "min     -35.224945  -369.150109  -579.490660  -251.495367          -75.143730   \n",
       "25%      18.732076    21.328936    17.124174     6.541236           -4.647636   \n",
       "50%      23.553828    27.574535    25.217098    15.144375           -0.140909   \n",
       "75%      27.759551    32.247539    30.746496    20.589852            3.965898   \n",
       "max      92.313766   408.180215   591.014113    69.694520          104.963158   \n",
       "\n",
       "       lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "count         2479.000000         2479.000000         2479.000000   \n",
       "mean             0.003397            0.554037            0.103880   \n",
       "std             39.383221           97.200697           14.461716   \n",
       "min           -728.743981        -1048.773622          -96.231800   \n",
       "25%             -3.342428           -6.773096           -4.498267   \n",
       "50%              0.180963            0.144378           -0.180041   \n",
       "75%              3.594742            7.305102            4.146319   \n",
       "max            512.648208          896.171353          172.660240   \n",
       "\n",
       "       lag1_mean_q1_0  lag1_mean_q1_1  ...   freq_669_3   freq_679_3  \\\n",
       "count     2479.000000     2479.000000  ...  2479.000000  2479.000000   \n",
       "mean        23.271148       26.809551  ...     0.008141     0.008063   \n",
       "std         17.639164       36.255490  ...     0.007653     0.007572   \n",
       "min       -351.810178     -800.320690  ...     0.000036     0.000024   \n",
       "25%         17.020349       20.684966  ...     0.002192     0.002169   \n",
       "50%         23.761987       27.442672  ...     0.006239     0.006029   \n",
       "75%         29.574478       32.720855  ...     0.011497     0.011610   \n",
       "max        116.412065      539.925670  ...     0.069699     0.058378   \n",
       "\n",
       "        freq_689_3   freq_699_3   freq_709_3   freq_720_3   freq_730_3  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000  2479.000000   \n",
       "mean      0.007784     0.007679     0.007413     0.007998     0.007449   \n",
       "std       0.007458     0.007276     0.007060     0.007547     0.006937   \n",
       "min       0.000018     0.000027     0.000052     0.000041     0.000008   \n",
       "25%       0.002108     0.002151     0.001930     0.002034     0.001985   \n",
       "50%       0.005735     0.005632     0.005532     0.006005     0.005717   \n",
       "75%       0.010986     0.011150     0.010645     0.011406     0.010768   \n",
       "max       0.086914     0.065296     0.053044     0.054104     0.060196   \n",
       "\n",
       "        freq_740_3   freq_750_3        Label  \n",
       "count  2479.000000  2479.000000  2479.000000  \n",
       "mean      0.007307     0.007382     1.004437  \n",
       "std       0.007379     0.007276     0.815743  \n",
       "min       0.000036     0.000048     0.000000  \n",
       "25%       0.002042     0.001964     0.000000  \n",
       "50%       0.005300     0.005315     1.000000  \n",
       "75%       0.010208     0.010330     2.000000  \n",
       "max       0.134037     0.071582     2.000000  \n",
       "\n",
       "[8 rows x 989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31849d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 988)\n",
      "(2479,)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['Label'],axis=1)\n",
    "y=df['Label'].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aa7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b84a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983, 988)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e69848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ASUS/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b839e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "mi_score = MIC(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60c7fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17510047, 0.16361595, 0.2630987 , 0.17896149, 0.07985233,\n",
       "       0.07370126, 0.18089221, 0.0817252 , 0.15252175, 0.13484112,\n",
       "       0.23454473, 0.12799083, 0.15090237, 0.14388438, 0.27188783,\n",
       "       0.13047333, 0.08922954, 0.05264589, 0.17408943, 0.08155563,\n",
       "       0.10480489, 0.08688588, 0.17497214, 0.06338879, 0.09333889,\n",
       "       0.08383702, 0.19754212, 0.06760815, 0.11037947, 0.0704142 ,\n",
       "       0.1679578 , 0.101911  , 0.10464602, 0.07541719, 0.17927817,\n",
       "       0.07431423, 0.16923765, 0.19661775, 0.43573472, 0.1126456 ,\n",
       "       0.10910521, 0.09645058, 0.12468961, 0.09930481, 0.0739746 ,\n",
       "       0.02682849, 0.05442962, 0.10079887, 0.19006953, 0.04953071,\n",
       "       0.16665449, 0.10916268, 0.19525678, 0.20104652, 0.36580989,\n",
       "       0.2250899 , 0.07866674, 0.079609  , 0.17637374, 0.0678371 ,\n",
       "       0.11801527, 0.13577491, 0.29143915, 0.14180232, 0.13682893,\n",
       "       0.17744481, 0.27485375, 0.15002384, 0.07486542, 0.06109614,\n",
       "       0.19593287, 0.0543823 , 0.07581947, 0.08005746, 0.19060691,\n",
       "       0.08417084, 0.06394415, 0.09236584, 0.18601956, 0.06565225,\n",
       "       0.10005919, 0.07178357, 0.15692751, 0.03672162, 0.0763246 ,\n",
       "       0.04994303, 0.18208126, 0.06576777, 0.23320565, 0.26014877,\n",
       "       0.43337546, 0.20253546, 0.09550139, 0.06939181, 0.16358599,\n",
       "       0.11022605, 0.15493625, 0.20102849, 0.33721243, 0.1331332 ,\n",
       "       0.17670713, 0.21009971, 0.32814061, 0.13728872, 0.1186428 ,\n",
       "       0.07575188, 0.18482969, 0.05692107, 0.08234422, 0.06980569,\n",
       "       0.1593754 , 0.07407089, 0.09027985, 0.07392815, 0.17448785,\n",
       "       0.09139007, 0.08936507, 0.07968549, 0.19119096, 0.08044445,\n",
       "       0.101834  , 0.07525672, 0.1963867 , 0.07865765, 0.16959362,\n",
       "       0.13591663, 0.3432139 , 0.13026367, 0.19674206, 0.27142512,\n",
       "       0.13876388, 0.43548579, 0.26653946, 0.1122287 , 0.4749401 ,\n",
       "       0.20499812, 0.09882176, 0.10279451, 0.17421445, 0.03116368,\n",
       "       0.07706452, 0.1185023 , 0.19264391, 0.09128586, 0.04922992,\n",
       "       0.43558017, 0.13417725, 0.1388953 , 0.10355212, 0.0507943 ,\n",
       "       0.03583676, 0.04062106, 0.03802944, 0.02565501, 0.02889381,\n",
       "       0.02313163, 0.01872019, 0.        , 0.04186866, 0.02173968,\n",
       "       0.0506597 , 0.0312019 , 0.05741157, 0.06238111, 0.05902482,\n",
       "       0.04437446, 0.03860723, 0.03928157, 0.06772426, 0.09289545,\n",
       "       0.13215548, 0.16558839, 0.1910561 , 0.17431639, 0.1610882 ,\n",
       "       0.16878042, 0.15209541, 0.14804625, 0.08407866, 0.04158833,\n",
       "       0.01932981, 0.03491031, 0.04185039, 0.01790873, 0.02151382,\n",
       "       0.00082813, 0.01607569, 0.02261261, 0.13813703, 0.15967001,\n",
       "       0.18800416, 0.19908899, 0.195622  , 0.18500035, 0.20550737,\n",
       "       0.25551183, 0.29624258, 0.300515  , 0.31719212, 0.32511516,\n",
       "       0.24969741, 0.2399203 , 0.22295731, 0.26262768, 0.25194835,\n",
       "       0.23760811, 0.24708634, 0.2680936 , 0.26872519, 0.2639146 ,\n",
       "       0.25944791, 0.24250356, 0.26071176, 0.25076091, 0.23418534,\n",
       "       0.22562864, 0.2542757 , 0.23671832, 0.2663546 , 0.2638248 ,\n",
       "       0.23080798, 0.24409478, 0.21190388, 0.21592341, 0.23078959,\n",
       "       0.23500513, 0.22202004, 0.23528676, 0.22894717, 0.24492706,\n",
       "       0.23168351, 0.22726195, 0.25065344, 0.22784145, 0.25889575,\n",
       "       0.22412164, 0.28909844, 0.25649247, 0.23221566, 0.2474031 ,\n",
       "       0.20465558, 0.23239394, 0.22112639, 0.23631451, 0.24468988,\n",
       "       0.22161   , 0.21429092, 0.21569549, 0.20560321, 0.23911284,\n",
       "       0.21396296, 0.21288435, 0.21758879, 0.21306269, 0.21011509,\n",
       "       0.21357627, 0.21878527, 0.20839652, 0.20414646, 0.22742675,\n",
       "       0.21087528, 0.21266252, 0.2018521 , 0.18895839, 0.19556273,\n",
       "       0.1992088 , 0.18977637, 0.19738477, 0.18635356, 0.19356032,\n",
       "       0.21553882, 0.2007375 , 0.17589397, 0.18793523, 0.21725889,\n",
       "       0.21308724, 0.23588588, 0.23399884, 0.22880367, 0.24360545,\n",
       "       0.36823687, 0.30764032, 0.21190031, 0.21997846, 0.21557891,\n",
       "       0.2006198 , 0.20072484, 0.21719605, 0.32553137, 0.2487899 ,\n",
       "       0.20222823, 0.23465029, 0.30227889, 0.20612001, 0.27239051,\n",
       "       0.22868207, 0.25501845, 0.22453638, 0.19758985, 0.19309815,\n",
       "       0.22492532, 0.28177847, 0.35470122, 0.22893226, 0.21230259,\n",
       "       0.21672851, 0.20805077, 0.2261953 , 0.28818554, 0.21830918,\n",
       "       0.29651898, 0.21007259, 0.203629  , 0.23626565, 0.26980594,\n",
       "       0.24724887, 0.25280634, 0.23633881, 0.2286797 , 0.23927443,\n",
       "       0.26571454, 0.34383053, 0.23080445, 0.23421125, 0.30988301,\n",
       "       0.23643378, 0.23617561, 0.26558666, 0.33148995, 0.30132553,\n",
       "       0.25266953, 0.28006349, 0.04171201, 0.04102149, 0.07351076,\n",
       "       0.08806085, 0.11150873, 0.14422076, 0.15664151, 0.16067787,\n",
       "       0.15743665, 0.16379139, 0.14172628, 0.17286373, 0.15640188,\n",
       "       0.14783062, 0.14470022, 0.12331004, 0.08861135, 0.05916374,\n",
       "       0.08382085, 0.06323848, 0.09492264, 0.03466963, 0.06054908,\n",
       "       0.08345221, 0.06192036, 0.06156022, 0.04363367, 0.05180902,\n",
       "       0.04787436, 0.02878103, 0.03070124, 0.0309897 , 0.04247715,\n",
       "       0.04120347, 0.04938225, 0.02458196, 0.0372718 , 0.02765523,\n",
       "       0.02465081, 0.04126428, 0.04508415, 0.05022962, 0.16141582,\n",
       "       0.04692721, 0.03609422, 0.04097711, 0.02107097, 0.05140831,\n",
       "       0.12207075, 0.07255485, 0.13144747, 0.02707457, 0.04604738,\n",
       "       0.05588565, 0.06536333, 0.03699146, 0.06703007, 0.0431223 ,\n",
       "       0.03948203, 0.04778417, 0.03973139, 0.20589609, 0.05528848,\n",
       "       0.04183045, 0.10846757, 0.06917313, 0.05093071, 0.08710212,\n",
       "       0.19533596, 0.1375714 , 0.07419119, 0.05625263, 0.23234929,\n",
       "       0.23711067, 0.22146763, 0.24380014, 0.21472715, 0.22109763,\n",
       "       0.24283606, 0.2559044 , 0.30511439, 0.32046599, 0.33615978,\n",
       "       0.32708767, 0.26856673, 0.24137143, 0.27656424, 0.25648116,\n",
       "       0.29428441, 0.28536706, 0.29150444, 0.29706146, 0.2746758 ,\n",
       "       0.27731283, 0.28910095, 0.27570978, 0.26153043, 0.26711518,\n",
       "       0.26189602, 0.26898314, 0.25728012, 0.25367499, 0.26530034,\n",
       "       0.24738097, 0.23181158, 0.25379844, 0.24870894, 0.26805528,\n",
       "       0.22395829, 0.24866953, 0.25656657, 0.24319291, 0.23845146,\n",
       "       0.24149562, 0.27599436, 0.23657887, 0.25911042, 0.24488042,\n",
       "       0.23914135, 0.23826809, 0.25611686, 0.27303143, 0.25569321,\n",
       "       0.25070839, 0.23023389, 0.23206131, 0.2546357 , 0.22788884,\n",
       "       0.2458171 , 0.22495034, 0.21797993, 0.24586112, 0.24372867,\n",
       "       0.24354614, 0.25029973, 0.24139718, 0.24537846, 0.21373795,\n",
       "       0.23123122, 0.21940822, 0.26585183, 0.24446305, 0.26079892,\n",
       "       0.23466937, 0.18156889, 0.15890013, 0.26860569, 0.17628757,\n",
       "       0.08246996, 0.07769276, 0.17718806, 0.08055596, 0.15188423,\n",
       "       0.1356007 , 0.23575344, 0.13145321, 0.14901302, 0.14038878,\n",
       "       0.26965342, 0.13467444, 0.14436497, 0.12736632, 0.23398961,\n",
       "       0.12620637, 0.14310628, 0.15399632, 0.26510237, 0.13573333,\n",
       "       0.08867375, 0.04964056, 0.17433977, 0.07980987, 0.10444456,\n",
       "       0.09148792, 0.17413632, 0.06632382, 0.09426313, 0.08426543,\n",
       "       0.1983678 , 0.06616896, 0.10560181, 0.0688156 , 0.16643817,\n",
       "       0.09812261, 0.10738483, 0.07444958, 0.18016089, 0.07291636,\n",
       "       0.09409921, 0.04828567, 0.18387322, 0.07662475, 0.16743662,\n",
       "       0.20027642, 0.43601802, 0.11734616, 0.10928489, 0.10183838,\n",
       "       0.12656851, 0.10083308, 0.07301211, 0.03056179, 0.05697054,\n",
       "       0.09959497, 0.18536796, 0.05015732, 0.16730559, 0.10311607,\n",
       "       0.19565807, 0.20466899, 0.3652573 , 0.22947494, 0.08406177,\n",
       "       0.08613054, 0.17495046, 0.07138805, 0.11679333, 0.14097113,\n",
       "       0.29398301, 0.13914726, 0.13370681, 0.17515708, 0.27864954,\n",
       "       0.15017834, 0.13163   , 0.16417892, 0.28625418, 0.13826906,\n",
       "       0.12358301, 0.14458359, 0.27507683, 0.13966901, 0.07456462,\n",
       "       0.0600487 , 0.19236202, 0.05696991, 0.07602038, 0.08442727,\n",
       "       0.19031737, 0.0797083 , 0.06074742, 0.0885385 , 0.18892698,\n",
       "       0.0629662 , 0.09433207, 0.07262531, 0.15426247, 0.04410769,\n",
       "       0.08039427, 0.0535326 , 0.17555157, 0.07235336, 0.064589  ,\n",
       "       0.08353504, 0.16916238, 0.05055095, 0.22941546, 0.25549856,\n",
       "       0.43056551, 0.20277043, 0.0984652 , 0.0695367 , 0.16194298,\n",
       "       0.1156618 , 0.14965222, 0.20004356, 0.33351925, 0.1346905 ,\n",
       "       0.17133142, 0.21341984, 0.3282076 , 0.13450386, 0.1613763 ,\n",
       "       0.20059862, 0.33631445, 0.10142475, 0.16703977, 0.20755733,\n",
       "       0.3287466 , 0.11882605, 0.12062171, 0.07687669, 0.18543067,\n",
       "       0.05888822, 0.07942575, 0.06609859, 0.15995501, 0.07553222,\n",
       "       0.09604459, 0.07853447, 0.17367889, 0.08665978, 0.09061371,\n",
       "       0.0761595 , 0.19266552, 0.08515796, 0.10458145, 0.07545612,\n",
       "       0.19787767, 0.07200457, 0.11554798, 0.06626611, 0.17073722,\n",
       "       0.0645698 , 0.16788108, 0.13797091, 0.34525874, 0.12950049,\n",
       "       0.20040401, 0.26923544, 0.14227488, 0.43567226, 0.27069281,\n",
       "       0.1170649 , 0.47624375, 0.20476821, 0.09987478, 0.10317795,\n",
       "       0.17473232, 0.03488982, 0.07780774, 0.11556831, 0.19593761,\n",
       "       0.09268803, 0.05254719, 0.43796148, 0.12860214, 0.1430583 ,\n",
       "       0.11104531, 0.07346177, 0.04030204, 0.04104533, 0.02339371,\n",
       "       0.04941647, 0.03347666, 0.00896419, 0.00519716, 0.00141371,\n",
       "       0.03179308, 0.01799619, 0.0222364 , 0.06780201, 0.05543712,\n",
       "       0.05990306, 0.05351011, 0.03867039, 0.0458477 , 0.03938867,\n",
       "       0.05497886, 0.12821387, 0.14370231, 0.16346894, 0.1884284 ,\n",
       "       0.18013343, 0.17692096, 0.14938624, 0.14714291, 0.14046356,\n",
       "       0.062838  , 0.01837359, 0.03676465, 0.02211597, 0.02506092,\n",
       "       0.03376129, 0.00685673, 0.0185128 , 0.03759716, 0.00966429,\n",
       "       0.14050498, 0.15890427, 0.18924645, 0.20069403, 0.194709  ,\n",
       "       0.18599226, 0.20566272, 0.25396064, 0.30161368, 0.30181985,\n",
       "       0.31943485, 0.3259159 , 0.25005959, 0.24183618, 0.2274208 ,\n",
       "       0.26658848, 0.25550898, 0.23630908, 0.25002788, 0.26874326,\n",
       "       0.26655087, 0.26439747, 0.26211539, 0.24015815, 0.26126448,\n",
       "       0.25289636, 0.23636855, 0.23041911, 0.25868016, 0.23557178,\n",
       "       0.26533114, 0.25740185, 0.23664154, 0.24927924, 0.21314133,\n",
       "       0.21747173, 0.23230679, 0.23288534, 0.21765369, 0.23945543,\n",
       "       0.23318406, 0.24453112, 0.23668316, 0.22675539, 0.25361115,\n",
       "       0.23001491, 0.25987906, 0.22891095, 0.28474692, 0.25936037,\n",
       "       0.23391162, 0.24836543, 0.20981388, 0.23266534, 0.21971332,\n",
       "       0.23534764, 0.24811069, 0.2252    , 0.21684573, 0.21923526,\n",
       "       0.20258576, 0.23733855, 0.21562708, 0.2160395 , 0.21586147,\n",
       "       0.21093344, 0.20865736, 0.21596241, 0.22299689, 0.20623364,\n",
       "       0.20807252, 0.23047738, 0.21056814, 0.21102067, 0.2008765 ,\n",
       "       0.18824341, 0.19793334, 0.19755939, 0.18470097, 0.1953906 ,\n",
       "       0.18848264, 0.19282507, 0.21777161, 0.20085816, 0.18039287,\n",
       "       0.19274132, 0.22190668, 0.20755087, 0.23665104, 0.24132758,\n",
       "       0.22711556, 0.23874619, 0.37016647, 0.30767363, 0.20980518,\n",
       "       0.2247121 , 0.22001716, 0.20285704, 0.20380031, 0.21838288,\n",
       "       0.32482818, 0.24906622, 0.19870377, 0.23225653, 0.30122368,\n",
       "       0.20482949, 0.2759927 , 0.2287073 , 0.25913171, 0.22282919,\n",
       "       0.1954806 , 0.19365877, 0.22510204, 0.28095348, 0.3562216 ,\n",
       "       0.22883895, 0.22223178, 0.21650274, 0.20961644, 0.22415039,\n",
       "       0.29501244, 0.2176888 , 0.29619692, 0.21121077, 0.2074784 ,\n",
       "       0.23744988, 0.26663735, 0.24467762, 0.25028713, 0.23610643,\n",
       "       0.22933189, 0.24264463, 0.26754797, 0.34843999, 0.23517545,\n",
       "       0.23362728, 0.30814635, 0.2360076 , 0.23738625, 0.27446308,\n",
       "       0.33329193, 0.30167018, 0.254217  , 0.28102161, 0.0372839 ,\n",
       "       0.04544997, 0.074203  , 0.08619255, 0.1165699 , 0.14540549,\n",
       "       0.15502434, 0.16586717, 0.15886861, 0.1688953 , 0.14380112,\n",
       "       0.17269687, 0.1489345 , 0.1475269 , 0.14694171, 0.12180453,\n",
       "       0.08856808, 0.06427572, 0.08074725, 0.06808637, 0.09630615,\n",
       "       0.03468206, 0.05453708, 0.08138151, 0.0575082 , 0.05579732,\n",
       "       0.03685911, 0.05387184, 0.04297219, 0.02656622, 0.03110972,\n",
       "       0.03051083, 0.0374916 , 0.04434591, 0.04977614, 0.01994373,\n",
       "       0.03336059, 0.03364034, 0.02512521, 0.04215976, 0.04954498,\n",
       "       0.05044097, 0.16007636, 0.04338775, 0.03897457, 0.04562135,\n",
       "       0.02115127, 0.04552491, 0.1220888 , 0.07439016, 0.13477455,\n",
       "       0.02981819, 0.04482883, 0.05439645, 0.06590074, 0.03919406,\n",
       "       0.07205851, 0.03677511, 0.03930875, 0.05107189, 0.04085182,\n",
       "       0.20572836, 0.05908647, 0.04182   , 0.10903815, 0.0665509 ,\n",
       "       0.05873411, 0.08179094, 0.19660194, 0.13987833, 0.07093728,\n",
       "       0.05491675, 0.23298523, 0.23232551, 0.22289277, 0.24264191,\n",
       "       0.21655877, 0.22693698, 0.2440465 , 0.25680358, 0.30703609,\n",
       "       0.32523258, 0.33597472, 0.32477086, 0.26629187, 0.2450753 ,\n",
       "       0.27422265, 0.25962866, 0.29525664, 0.28360702, 0.29192996,\n",
       "       0.29534852, 0.27443712, 0.2764301 , 0.29286721, 0.27677252,\n",
       "       0.26304729, 0.26913933, 0.26599366, 0.26874859, 0.25537717,\n",
       "       0.25679145, 0.26304136, 0.24952334, 0.23143275, 0.25680603,\n",
       "       0.25430886, 0.27136051, 0.22660587, 0.25220464, 0.25456315,\n",
       "       0.2470973 , 0.24075571, 0.23979104, 0.2756164 , 0.23420395,\n",
       "       0.26004174, 0.24683922, 0.23799455, 0.23896105, 0.25813354,\n",
       "       0.26944785, 0.25203105, 0.24782916, 0.22881465, 0.2300157 ,\n",
       "       0.25598874, 0.22829028, 0.24746086, 0.21968803, 0.21995564,\n",
       "       0.24237532, 0.24160497, 0.24218474, 0.24694443, 0.24715311,\n",
       "       0.23779223, 0.2154071 , 0.22932766, 0.21378342, 0.2699123 ,\n",
       "       0.2463926 , 0.26180533, 0.23952887])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49ee1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = pd.Series(mi_score, index=x.columns)\n",
    "mi_score = (mi_score*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c1018b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features1 = mi_score[:-364].index # 2184. 10% MI-score\n",
    "top_features2 = mi_score[:-552].index # 1996. 20% MI-score\n",
    "top_features3 = mi_score[:-1095].index # 1453. 30% MI-score\n",
    "top_features4 = mi_score[:-1960].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f15360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eigenval_0', 'lag1_eigenval_0', 'logcovM_2_2', 'std_2', 'lag1_std_2',\n",
       "       'covM_2_2', 'lag1_logcovM_2_2', 'lag1_covM_2_2', 'lag1_min_2', 'min_2',\n",
       "       ...\n",
       "       'topFreq_10_2', 'mean_q2_1', 'freq_730_2', 'max_q4_3', 'max_q1_3',\n",
       "       'lag1_logcovM_3_3', 'lag1_covM_1_3', 'max_q3_3', 'lag1_freq_010_0',\n",
       "       'covM_0_1'],\n",
       "      dtype='object', length=624)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1ff4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = StandardScaler().fit_transform(x[top_features1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db0bea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, random_state=42, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64503a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983, 624)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c36946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1983 Test set: 496\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\",len(X_train), \"Test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6dcf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d111a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters1, filters2, kernel_size1, kernel_size2, dropout1, dropout2):\n",
    "\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv1D(filters1, kernel_size1, input_shape=(X_train.shape[1], 1)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout1))\n",
    "\n",
    "  model.add(layers.Conv1D(filters2, kernel_size2))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "196d88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ey3bon13) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.838 MB of 0.838 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▅▁▆▃▄▄█▆▅▇▃▂▄</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>loss</td><td>█▄▄▃▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▃█▄▅▄▄▃▁▅▅▅▂▃</td></tr><tr><td>val_loss</td><td>▄▆▅█▄▂▃▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.33894</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>1.10578</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>loss</td><td>1.11978</td></tr><tr><td>val_accuracy</td><td>0.31048</td></tr><tr><td>val_loss</td><td>1.11576</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stellar-sound-3</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/ey3bon13\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/ey3bon13</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220701_224502-ey3bon13\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ey3bon13). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ASUS\\Documents\\Mental-state\\wandb\\run-20220701_224717-2wa8wpac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/2wa8wpac\" target=\"_blank\">dulcet-grass-4</a></strong> to <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 620, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 620, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 620, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 310, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 310, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 306, 64)           20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 306, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 306, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 153, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 153, 64)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 29379     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,819\n",
      "Trainable params: 50,563\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='eeg-mental_state-classification',\n",
    "                 config={  # and include hyperparameters and metadata\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 30,\n",
    "                     \"batch_size\": 28,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"filters1\": 64,\n",
    "                     \"filters2\": 64,\n",
    "                     \"kernel_size1\": 5,\n",
    "                     \"kernel_size2\" : 5,\n",
    "                     \"dropout1\": 0.5,\n",
    "                     \"dropout2\": 0.5\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our experiment\n",
    "\n",
    "# Initialize model like you usually do.\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model(config.filters1, config.filters2, config.kernel_size1, config.kernel_size2, config.dropout1, config.dropout2)\n",
    "model.summary()\n",
    "\n",
    "# Compile model like you usually do.\n",
    "# Notice that we use config, so our metadata matches what gets executed\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a78d680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 624, 1), found shape=(None, 988)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16696/1089616070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 624, 1), found shape=(None, 988)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          epochs=config.epochs, \n",
    "          batch_size=config.batch_size,\n",
    "          validation_split=0.25,\n",
    "          shuffle=True,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f17d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5637 - accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.838 MB of 0.838 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▂▂▃▃▂▃▄▅▄▅▆▆▆▇▆▆▇▇▇████▅█▇███</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>██▆▆▆▆▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▁▂▆▂▂▃▅▄▄▅▇▃▄▆▆▆▆▅█▅▇▃▄▃▅▇▇▆▇</td></tr><tr><td>val_loss</td><td>█▅▆█▅▇▄▄▃▃▄▃▂▂▂▂▂▂▂▁▂▁▁▂▂▃▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.75202</td></tr><tr><td>accuracy</td><td>0.75925</td></tr><tr><td>best_epoch</td><td>29</td></tr><tr><td>best_val_loss</td><td>0.55919</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.5695</td></tr><tr><td>val_accuracy</td><td>0.78024</td></tr><tr><td>val_loss</td><td>0.55919</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crisp-jazz-2</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/36t52y87\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/36t52y87</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220701_213739-36t52y87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# With wandb.log, we can easily pass in metrics as key-value pairs.\n",
    "wandb.log({'Test Accuracy': accuracy})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4522f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
