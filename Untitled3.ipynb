{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc1420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca111dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0       33.965587  ...    0.000230    0.000351    0.000547    0.000381   \n",
       "1       40.893307  ...    0.001671    0.000740    0.001122    0.000521   \n",
       "2       30.692883  ...    0.000748    0.000569    0.000327    0.000197   \n",
       "3       20.777411  ...    0.000990    0.005644    0.006891    0.010546   \n",
       "4       32.658163  ...    0.001659    0.014379    0.014492    0.002949   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.000350    0.000453    0.000442    0.000325    0.000209    2.0  \n",
       "1    0.000624    0.000439    0.001249    0.000727    0.000801    2.0  \n",
       "2    0.000833    0.000909    0.000699    0.001165    0.000616    2.0  \n",
       "3    0.009583    0.011158    0.008853    0.004551    0.002287    1.0  \n",
       "4    0.004575    0.008305    0.007202    0.006957    0.009836    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472d63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lag1_mean_0           False\n",
       "lag1_mean_1           False\n",
       "lag1_mean_2           False\n",
       "lag1_mean_3           False\n",
       "lag1_mean_d_h2h1_0    False\n",
       "                      ...  \n",
       "freq_720_3            False\n",
       "freq_730_3            False\n",
       "freq_740_3            False\n",
       "freq_750_3            False\n",
       "Label                 False\n",
       "Length: 989, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecde7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "      <td>2479.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.584351</td>\n",
       "      <td>27.060411</td>\n",
       "      <td>20.452931</td>\n",
       "      <td>11.526044</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.554037</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>23.271148</td>\n",
       "      <td>26.809551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>1.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.543938</td>\n",
       "      <td>24.252348</td>\n",
       "      <td>72.104439</td>\n",
       "      <td>19.196870</td>\n",
       "      <td>13.382998</td>\n",
       "      <td>39.383221</td>\n",
       "      <td>97.200697</td>\n",
       "      <td>14.461716</td>\n",
       "      <td>17.639164</td>\n",
       "      <td>36.255490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.815743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.224945</td>\n",
       "      <td>-369.150109</td>\n",
       "      <td>-579.490660</td>\n",
       "      <td>-251.495367</td>\n",
       "      <td>-75.143730</td>\n",
       "      <td>-728.743981</td>\n",
       "      <td>-1048.773622</td>\n",
       "      <td>-96.231800</td>\n",
       "      <td>-351.810178</td>\n",
       "      <td>-800.320690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.732076</td>\n",
       "      <td>21.328936</td>\n",
       "      <td>17.124174</td>\n",
       "      <td>6.541236</td>\n",
       "      <td>-4.647636</td>\n",
       "      <td>-3.342428</td>\n",
       "      <td>-6.773096</td>\n",
       "      <td>-4.498267</td>\n",
       "      <td>17.020349</td>\n",
       "      <td>20.684966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.553828</td>\n",
       "      <td>27.574535</td>\n",
       "      <td>25.217098</td>\n",
       "      <td>15.144375</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>-0.180041</td>\n",
       "      <td>23.761987</td>\n",
       "      <td>27.442672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.759551</td>\n",
       "      <td>32.247539</td>\n",
       "      <td>30.746496</td>\n",
       "      <td>20.589852</td>\n",
       "      <td>3.965898</td>\n",
       "      <td>3.594742</td>\n",
       "      <td>7.305102</td>\n",
       "      <td>4.146319</td>\n",
       "      <td>29.574478</td>\n",
       "      <td>32.720855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.313766</td>\n",
       "      <td>408.180215</td>\n",
       "      <td>591.014113</td>\n",
       "      <td>69.694520</td>\n",
       "      <td>104.963158</td>\n",
       "      <td>512.648208</td>\n",
       "      <td>896.171353</td>\n",
       "      <td>172.660240</td>\n",
       "      <td>116.412065</td>\n",
       "      <td>539.925670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.058378</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>0.053044</td>\n",
       "      <td>0.054104</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>0.071582</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000         2479.000000   \n",
       "mean     23.584351    27.060411    20.452931    11.526044            0.014449   \n",
       "std      10.543938    24.252348    72.104439    19.196870           13.382998   \n",
       "min     -35.224945  -369.150109  -579.490660  -251.495367          -75.143730   \n",
       "25%      18.732076    21.328936    17.124174     6.541236           -4.647636   \n",
       "50%      23.553828    27.574535    25.217098    15.144375           -0.140909   \n",
       "75%      27.759551    32.247539    30.746496    20.589852            3.965898   \n",
       "max      92.313766   408.180215   591.014113    69.694520          104.963158   \n",
       "\n",
       "       lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "count         2479.000000         2479.000000         2479.000000   \n",
       "mean             0.003397            0.554037            0.103880   \n",
       "std             39.383221           97.200697           14.461716   \n",
       "min           -728.743981        -1048.773622          -96.231800   \n",
       "25%             -3.342428           -6.773096           -4.498267   \n",
       "50%              0.180963            0.144378           -0.180041   \n",
       "75%              3.594742            7.305102            4.146319   \n",
       "max            512.648208          896.171353          172.660240   \n",
       "\n",
       "       lag1_mean_q1_0  lag1_mean_q1_1  ...   freq_669_3   freq_679_3  \\\n",
       "count     2479.000000     2479.000000  ...  2479.000000  2479.000000   \n",
       "mean        23.271148       26.809551  ...     0.008141     0.008063   \n",
       "std         17.639164       36.255490  ...     0.007653     0.007572   \n",
       "min       -351.810178     -800.320690  ...     0.000036     0.000024   \n",
       "25%         17.020349       20.684966  ...     0.002192     0.002169   \n",
       "50%         23.761987       27.442672  ...     0.006239     0.006029   \n",
       "75%         29.574478       32.720855  ...     0.011497     0.011610   \n",
       "max        116.412065      539.925670  ...     0.069699     0.058378   \n",
       "\n",
       "        freq_689_3   freq_699_3   freq_709_3   freq_720_3   freq_730_3  \\\n",
       "count  2479.000000  2479.000000  2479.000000  2479.000000  2479.000000   \n",
       "mean      0.007784     0.007679     0.007413     0.007998     0.007449   \n",
       "std       0.007458     0.007276     0.007060     0.007547     0.006937   \n",
       "min       0.000018     0.000027     0.000052     0.000041     0.000008   \n",
       "25%       0.002108     0.002151     0.001930     0.002034     0.001985   \n",
       "50%       0.005735     0.005632     0.005532     0.006005     0.005717   \n",
       "75%       0.010986     0.011150     0.010645     0.011406     0.010768   \n",
       "max       0.086914     0.065296     0.053044     0.054104     0.060196   \n",
       "\n",
       "        freq_740_3   freq_750_3        Label  \n",
       "count  2479.000000  2479.000000  2479.000000  \n",
       "mean      0.007307     0.007382     1.004437  \n",
       "std       0.007379     0.007276     0.815743  \n",
       "min       0.000036     0.000048     0.000000  \n",
       "25%       0.002042     0.001964     0.000000  \n",
       "50%       0.005300     0.005315     1.000000  \n",
       "75%       0.010208     0.010330     2.000000  \n",
       "max       0.134037     0.071582     2.000000  \n",
       "\n",
       "[8 rows x 989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31849d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 988)\n",
      "(2479,)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['Label'],axis=1)\n",
    "y=df['Label'].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aa7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b84a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983, 988)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e69848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmadhyam_2001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b839e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "# mi_score = MIC(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ee1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_score = pd.Series(mi_score, index=x.columns)\n",
    "# mi_score = (mi_score*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1018b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features1 = mi_score[:-364].index # 2184. 10% MI-score\n",
    "# top_features2 = mi_score[:-552].index # 1996. 20% MI-score\n",
    "# top_features3 = mi_score[:-1095].index # 1453. 30% MI-score\n",
    "# top_features4 = mi_score[:-1960].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dcf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d111a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(filters1, filters2, kernel_size1, kernel_size2, dropout1, dropout2):\n",
    "\n",
    "  model=models.Sequential()\n",
    "  model.add(layers.Conv1D(filters1, kernel_size1, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout1))\n",
    "  model.add(layers.ReLU())\n",
    "\n",
    "  model.add(layers.Conv1D(filters2, kernel_size2,activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPool1D(2))\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "  model.add(layers.ReLU())\n",
    "#   model.add(layers.Flatten())\n",
    "    \n",
    "  model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.GlobalMaxPooling1D())\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "  model.add(layers.ReLU())\n",
    "  model.add(layers.Flatten())\n",
    "  \n",
    "  model.add(layers.Dense(32, activation='relu'))\n",
    "  model.add(layers.Dropout(dropout2))\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "196d88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:250c5dnm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.464 MB of 0.464 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▄▃▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▂█▇▆▂▂▁</td></tr><tr><td>val_loss</td><td>▃█▃▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.01292</td></tr><tr><td>accuracy</td><td>0.59718</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.90631</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>1.18324</td></tr><tr><td>val_accuracy</td><td>0.55847</td></tr><tr><td>val_loss</td><td>0.90809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-paper-11</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/250c5dnm\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/250c5dnm</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220706_234356-250c5dnm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:250c5dnm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ASUS\\Documents\\Mental_State_Classification\\wandb\\run-20220706_234625-2r6hc7ih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/2r6hc7ih\" target=\"_blank\">tough-frost-12</a></strong> to <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 984, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 984, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 492, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 492, 64)           0         \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 492, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 488, 64)           20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 488, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 244, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 244, 64)           0         \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 244, 64)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 242, 32)           6176      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 242, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,899\n",
      "Trainable params: 28,579\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='eeg-mental_state-classification',\n",
    "                 config={  \n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 30,\n",
    "                     \"batch_size\": 28,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"filters1\": 64,\n",
    "                     \"filters2\": 64,\n",
    "                     \"kernel_size1\": 5,\n",
    "                     \"kernel_size2\" : 5,\n",
    "                     \"dropout1\": 0.5,\n",
    "                     \"dropout2\": 0.5\n",
    "                 })\n",
    "config = wandb.config\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model(config.filters1, config.filters2, config.kernel_size1, config.kernel_size2, config.dropout1, config.dropout2)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a78d680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 12s 165ms/step - loss: 4.4105 - accuracy: 0.4243 - val_loss: 2.6610 - val_accuracy: 0.5544 - _timestamp: 1657131427.0000 - _runtime: 35.0000\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 2.8126 - accuracy: 0.5084 - val_loss: 1.9560 - val_accuracy: 0.5847 - _timestamp: 1657131435.0000 - _runtime: 43.0000\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 2.4028 - accuracy: 0.5239 - val_loss: 1.7021 - val_accuracy: 0.5827 - _timestamp: 1657131444.0000 - _runtime: 52.0000\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 8s 152ms/step - loss: 2.2146 - accuracy: 0.5104 - val_loss: 1.4656 - val_accuracy: 0.5746 - _timestamp: 1657131452.0000 - _runtime: 60.0000\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 1.5508 - accuracy: 0.5440 - val_loss: 1.2332 - val_accuracy: 0.5524 - _timestamp: 1657131460.0000 - _runtime: 68.0000\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 8s 155ms/step - loss: 1.5533 - accuracy: 0.5474 - val_loss: 1.0973 - val_accuracy: 0.5423 - _timestamp: 1657131468.0000 - _runtime: 76.0000\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 1.3042 - accuracy: 0.5514 - val_loss: 1.0329 - val_accuracy: 0.5081 - _timestamp: 1657131476.0000 - _runtime: 84.0000\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 8s 156ms/step - loss: 1.1728 - accuracy: 0.5662 - val_loss: 0.9850 - val_accuracy: 0.6129 - _timestamp: 1657131485.0000 - _runtime: 93.0000\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 1.2572 - accuracy: 0.5420 - val_loss: 0.9483 - val_accuracy: 0.5504 - _timestamp: 1657131493.0000 - _runtime: 101.0000\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 1.0733 - accuracy: 0.5461 - val_loss: 0.9228 - val_accuracy: 0.5363 - _timestamp: 1657131501.0000 - _runtime: 109.0000\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 1.0674 - accuracy: 0.5319 - val_loss: 0.9182 - val_accuracy: 0.5242 - _timestamp: 1657131509.0000 - _runtime: 117.0000\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 1.0659 - accuracy: 0.5662 - val_loss: 0.9376 - val_accuracy: 0.4536 - _timestamp: 1657131517.0000 - _runtime: 125.0000\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 1.0246 - accuracy: 0.5649 - val_loss: 0.9261 - val_accuracy: 0.4778 - _timestamp: 1657131525.0000 - _runtime: 133.0000\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 8s 152ms/step - loss: 1.0012 - accuracy: 0.5636 - val_loss: 0.9333 - val_accuracy: 0.4657 - _timestamp: 1657131534.0000 - _runtime: 142.0000\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 8s 147ms/step - loss: 0.9879 - accuracy: 0.5555 - val_loss: 0.9218 - val_accuracy: 0.4738 - _timestamp: 1657131542.0000 - _runtime: 150.0000\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.9607 - accuracy: 0.5797 - val_loss: 0.9234 - val_accuracy: 0.4637 - _timestamp: 1657131550.0000 - _runtime: 158.0000\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 0.8909 - accuracy: 0.5743 - val_loss: 0.9159 - val_accuracy: 0.4637 - _timestamp: 1657131558.0000 - _runtime: 166.0000\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 0.9424 - accuracy: 0.5656 - val_loss: 0.9137 - val_accuracy: 0.4657 - _timestamp: 1657131566.0000 - _runtime: 174.0000\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 0.9080 - accuracy: 0.5831 - val_loss: 0.9039 - val_accuracy: 0.4819 - _timestamp: 1657131574.0000 - _runtime: 182.0000\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 8s 153ms/step - loss: 0.8699 - accuracy: 0.5723 - val_loss: 0.9032 - val_accuracy: 0.4698 - _timestamp: 1657131582.0000 - _runtime: 190.0000\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.9307 - accuracy: 0.5656 - val_loss: 0.9087 - val_accuracy: 0.4556 - _timestamp: 1657131590.0000 - _runtime: 198.0000\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 8s 147ms/step - loss: 0.8663 - accuracy: 0.5709 - val_loss: 0.8981 - val_accuracy: 0.4637 - _timestamp: 1657131598.0000 - _runtime: 206.0000\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.8383 - accuracy: 0.5797 - val_loss: 0.8899 - val_accuracy: 0.4859 - _timestamp: 1657131606.0000 - _runtime: 214.0000\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.9259 - accuracy: 0.5810 - val_loss: 0.8828 - val_accuracy: 0.4899 - _timestamp: 1657131614.0000 - _runtime: 222.0000\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 8s 156ms/step - loss: 0.8877 - accuracy: 0.5864 - val_loss: 0.8777 - val_accuracy: 0.4960 - _timestamp: 1657131623.0000 - _runtime: 231.0000\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 8s 153ms/step - loss: 0.8502 - accuracy: 0.5817 - val_loss: 0.8833 - val_accuracy: 0.4839 - _timestamp: 1657131631.0000 - _runtime: 239.0000\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 0.8622 - accuracy: 0.5689 - val_loss: 0.8742 - val_accuracy: 0.4940 - _timestamp: 1657131639.0000 - _runtime: 247.0000\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 8s 147ms/step - loss: 0.8464 - accuracy: 0.5891 - val_loss: 0.8795 - val_accuracy: 0.4798 - _timestamp: 1657131647.0000 - _runtime: 255.0000\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 9s 161ms/step - loss: 0.8400 - accuracy: 0.5898 - val_loss: 0.8658 - val_accuracy: 0.5020 - _timestamp: 1657131656.0000 - _runtime: 264.0000\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 9s 175ms/step - loss: 0.8337 - accuracy: 0.5871 - val_loss: 0.8600 - val_accuracy: 0.5040 - _timestamp: 1657131665.0000 - _runtime: 273.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          epochs=config.epochs, \n",
    "          batch_size=config.batch_size,\n",
    "          validation_split=0.25,\n",
    "          shuffle=False,\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f17d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 28ms/step - loss: 0.5509 - accuracy: 0.7298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.859 MB of 1.859 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▃▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▃▃▅▅▄▄▄▅▅▅▄▆▄▅▆▆▆▇▅▆▆▅▆▆▇▇█▇</td></tr><tr><td>val_loss</td><td>█▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.01304</td></tr><tr><td>Test Accuracy</td><td>0.72984</td></tr><tr><td>accuracy</td><td>0.77001</td></tr><tr><td>best_epoch</td><td>29</td></tr><tr><td>best_val_loss</td><td>0.53995</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.54063</td></tr><tr><td>val_accuracy</td><td>0.77016</td></tr><tr><td>val_loss</td><td>0.53995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lyric-jazz-9</strong>: <a href=\"https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/249iw04w\" target=\"_blank\">https://wandb.ai/madhyam_2001/eeg-mental_state-classification/runs/249iw04w</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220706_232354-249iw04w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "wandb.log({'Test Accuracy': accuracy})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4522f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
