{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b9995ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "74e29c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('mental-state.csv')\n",
    "data_new= pd.get_dummies(df, columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6c573210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_659_3</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 988 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_659_3  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0       33.965587  ...    0.000579    0.000230    0.000351    0.000547   \n",
       "1       40.893307  ...    0.000448    0.001671    0.000740    0.001122   \n",
       "2       30.692883  ...    0.001028    0.000748    0.000569    0.000327   \n",
       "3       20.777411  ...    0.015502    0.000990    0.005644    0.006891   \n",
       "4       32.658163  ...    0.013212    0.001659    0.014379    0.014492   \n",
       "\n",
       "   freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \n",
       "0    0.000381    0.000350    0.000453    0.000442    0.000325    0.000209  \n",
       "1    0.000521    0.000624    0.000439    0.001249    0.000727    0.000801  \n",
       "2    0.000197    0.000833    0.000909    0.000699    0.001165    0.000616  \n",
       "3    0.010546    0.009583    0.011158    0.008853    0.004551    0.002287  \n",
       "4    0.002949    0.004575    0.008305    0.007202    0.006957    0.009836  \n",
       "\n",
       "[5 rows x 988 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data_new.loc[:,'lag1_mean_0':'freq_750_3']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61924bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label_0.0  Label_1.0  Label_2.0\n",
       "0          0          0          1\n",
       "1          0          0          1\n",
       "2          0          0          1\n",
       "3          0          1          0\n",
       "4          0          0          1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data_new.loc[:,'Label_0.0':'Label_2.0']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b7d85337",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d93076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c25bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "625144c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_pca = pd.concat([pd.DataFrame(X_pca), y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cebd16ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>Label_0.0</th>\n",
       "      <th>Label_1.0</th>\n",
       "      <th>Label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-21.044050</td>\n",
       "      <td>-0.010535</td>\n",
       "      <td>0.718237</td>\n",
       "      <td>-2.682393</td>\n",
       "      <td>4.193227</td>\n",
       "      <td>-1.814457</td>\n",
       "      <td>1.506927</td>\n",
       "      <td>-7.564069</td>\n",
       "      <td>5.086255</td>\n",
       "      <td>-2.217937</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.306918</td>\n",
       "      <td>0.227764</td>\n",
       "      <td>0.756084</td>\n",
       "      <td>-1.547749</td>\n",
       "      <td>0.490091</td>\n",
       "      <td>1.025926</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24.072607</td>\n",
       "      <td>-9.930574</td>\n",
       "      <td>-12.967207</td>\n",
       "      <td>2.545072</td>\n",
       "      <td>5.526551</td>\n",
       "      <td>-3.177310</td>\n",
       "      <td>-0.278590</td>\n",
       "      <td>1.138539</td>\n",
       "      <td>0.579483</td>\n",
       "      <td>1.883216</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.326977</td>\n",
       "      <td>1.266401</td>\n",
       "      <td>0.123532</td>\n",
       "      <td>0.620789</td>\n",
       "      <td>2.078735</td>\n",
       "      <td>-1.663094</td>\n",
       "      <td>-0.958898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.926461</td>\n",
       "      <td>-3.452873</td>\n",
       "      <td>-3.501628</td>\n",
       "      <td>-1.068487</td>\n",
       "      <td>0.706277</td>\n",
       "      <td>2.762854</td>\n",
       "      <td>-2.036844</td>\n",
       "      <td>-2.407663</td>\n",
       "      <td>-1.345975</td>\n",
       "      <td>1.013190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.570548</td>\n",
       "      <td>0.245745</td>\n",
       "      <td>0.709826</td>\n",
       "      <td>-0.379645</td>\n",
       "      <td>0.571367</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>-0.258072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.600035</td>\n",
       "      <td>-1.355738</td>\n",
       "      <td>1.934047</td>\n",
       "      <td>-1.049669</td>\n",
       "      <td>-1.309943</td>\n",
       "      <td>-1.622926</td>\n",
       "      <td>-0.501734</td>\n",
       "      <td>0.973511</td>\n",
       "      <td>-0.773587</td>\n",
       "      <td>-1.199485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494932</td>\n",
       "      <td>-0.147908</td>\n",
       "      <td>0.708309</td>\n",
       "      <td>-0.165715</td>\n",
       "      <td>-1.807516</td>\n",
       "      <td>-1.320308</td>\n",
       "      <td>0.410463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.194237</td>\n",
       "      <td>23.783829</td>\n",
       "      <td>-8.415842</td>\n",
       "      <td>3.450492</td>\n",
       "      <td>-3.116790</td>\n",
       "      <td>1.795192</td>\n",
       "      <td>-0.232985</td>\n",
       "      <td>-0.756297</td>\n",
       "      <td>-5.876472</td>\n",
       "      <td>-1.407715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562077</td>\n",
       "      <td>0.401398</td>\n",
       "      <td>2.428464</td>\n",
       "      <td>-0.582994</td>\n",
       "      <td>2.149580</td>\n",
       "      <td>-1.959568</td>\n",
       "      <td>-2.471454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4         5         6  \\\n",
       "0 -21.044050  -0.010535   0.718237 -2.682393  4.193227 -1.814457  1.506927   \n",
       "1 -24.072607  -9.930574 -12.967207  2.545072  5.526551 -3.177310 -0.278590   \n",
       "2 -22.926461  -3.452873  -3.501628 -1.068487  0.706277  2.762854 -2.036844   \n",
       "3   8.600035  -1.355738   1.934047 -1.049669 -1.309943 -1.622926 -0.501734   \n",
       "4  12.194237  23.783829  -8.415842  3.450492 -3.116790  1.795192 -0.232985   \n",
       "\n",
       "          7         8         9  ...        57        58        59        60  \\\n",
       "0 -7.564069  5.086255 -2.217937  ... -1.306918  0.227764  0.756084 -1.547749   \n",
       "1  1.138539  0.579483  1.883216  ... -1.326977  1.266401  0.123532  0.620789   \n",
       "2 -2.407663 -1.345975  1.013190  ... -0.570548  0.245745  0.709826 -0.379645   \n",
       "3  0.973511 -0.773587 -1.199485  ... -0.494932 -0.147908  0.708309 -0.165715   \n",
       "4 -0.756297 -5.876472 -1.407715  ... -0.562077  0.401398  2.428464 -0.582994   \n",
       "\n",
       "         61        62        63  Label_0.0  Label_1.0  Label_2.0  \n",
       "0  0.490091  1.025926  0.077259          0          0          1  \n",
       "1  2.078735 -1.663094 -0.958898          0          0          1  \n",
       "2  0.571367 -0.000776 -0.258072          0          0          1  \n",
       "3 -1.807516 -1.320308  0.410463          0          1          0  \n",
       "4  2.149580 -1.959568 -2.471454          0          0          1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f5857aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b8f880c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d2082d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "efs=ExhaustiveFeatureSelector(RandomForestClassifier(), min_features=4,max_features=8,scoring='roc_auc',cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "26c18d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efs.fit(pd.DataFrame(X_pca),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad19b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b6506721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7b295a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='minority')\n",
    "x_sm,y_sm=smote.fit_resample(X_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ea5f98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_sm,y_sm,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a6a86db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1992, 64), (1992, 3), (498, 64), (498, 3))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5f9d4846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "12932712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fccdf430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 60, 64)            384       \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 60, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling1d_4 (Averag  (None, 30, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 64)            0         \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 30, 64)            0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 26, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 26, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling1d_5 (Averag  (None, 13, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 13, 64)            0         \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 13, 64)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 2499      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,963\n",
      "Trainable params: 56,707\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(64, 5, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(64, 5,activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation='softmax'))   \n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "491cf2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - 4s 43ms/step - loss: 0.7094 - accuracy: 0.7242 - val_loss: 1.0471 - val_accuracy: 0.7811\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.3495 - accuracy: 0.8668 - val_loss: 1.0282 - val_accuracy: 0.8052\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.2695 - accuracy: 0.8969 - val_loss: 0.9677 - val_accuracy: 0.8353\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.2317 - accuracy: 0.9150 - val_loss: 0.9103 - val_accuracy: 0.8755\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.2078 - accuracy: 0.9290 - val_loss: 0.7946 - val_accuracy: 0.8936\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1684 - accuracy: 0.9351 - val_loss: 0.6497 - val_accuracy: 0.9337\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1610 - accuracy: 0.9351 - val_loss: 0.5280 - val_accuracy: 0.9157\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1284 - accuracy: 0.9505 - val_loss: 0.3681 - val_accuracy: 0.9277\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1175 - accuracy: 0.9605 - val_loss: 0.2839 - val_accuracy: 0.9177\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1098 - accuracy: 0.9552 - val_loss: 0.2391 - val_accuracy: 0.9357\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1000 - accuracy: 0.9625 - val_loss: 0.2238 - val_accuracy: 0.9197\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0947 - accuracy: 0.9659 - val_loss: 0.1750 - val_accuracy: 0.9398\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0849 - accuracy: 0.9726 - val_loss: 0.1696 - val_accuracy: 0.9458\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0815 - accuracy: 0.9732 - val_loss: 0.1789 - val_accuracy: 0.9337\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.1592 - val_accuracy: 0.9518\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.1979 - val_accuracy: 0.9357\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.1944 - val_accuracy: 0.9538\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.1427 - val_accuracy: 0.9518\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 0.1545 - val_accuracy: 0.9478\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.1947 - val_accuracy: 0.9438\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0514 - accuracy: 0.9813 - val_loss: 0.2046 - val_accuracy: 0.9418\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0396 - accuracy: 0.9893 - val_loss: 0.1739 - val_accuracy: 0.9438\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.1761 - val_accuracy: 0.9478\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 0.1685 - val_accuracy: 0.9458\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0360 - accuracy: 0.9873 - val_loss: 0.1442 - val_accuracy: 0.9478\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 0.1812 - val_accuracy: 0.9438\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0441 - accuracy: 0.9833 - val_loss: 0.1736 - val_accuracy: 0.9558\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0294 - accuracy: 0.9946 - val_loss: 0.1333 - val_accuracy: 0.9538\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.1671 - val_accuracy: 0.9538\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.1908 - val_accuracy: 0.9458\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.2090 - val_accuracy: 0.9398\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.1720 - val_accuracy: 0.9498\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.1377 - val_accuracy: 0.9659\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.1701 - val_accuracy: 0.9578\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.1881 - val_accuracy: 0.9458\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.1274 - val_accuracy: 0.9498\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.1427 - val_accuracy: 0.9578\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1380 - val_accuracy: 0.9518\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.1541 - val_accuracy: 0.9598\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.2097 - val_accuracy: 0.9438\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.2286 - val_accuracy: 0.9458\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.2213 - val_accuracy: 0.9558\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.1626 - val_accuracy: 0.9578\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1687 - val_accuracy: 0.9618\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.1808 - val_accuracy: 0.9498\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.1865 - val_accuracy: 0.9478\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.1684 - val_accuracy: 0.9498\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.2188 - val_accuracy: 0.9458\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0164 - accuracy: 0.9926 - val_loss: 0.2692 - val_accuracy: 0.9478\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0224 - accuracy: 0.9900 - val_loss: 0.2273 - val_accuracy: 0.9458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a4297f610>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=35,epochs=50,verbose=1,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bd02434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "34dfcf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1992, 3)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ca09cdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc241109",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1=np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "58b7c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c2255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "babcb8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:33:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_classes=3, num_parallel_tree=1,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_classes=3, num_parallel_tree=1,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
       "              n_jobs=0, num_classes=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=5, objective='multi:softprob', n_estimators=1000, \n",
    "                        num_classes=3)\n",
    "\n",
    "clf.fit(x_train, y_train1)  \n",
    "# train1 = clf.predict_proba(train_data)\n",
    "# test1 = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3d9ee0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = clf.predict_proba(x_train)\n",
    "pred = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fcbe76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d598303c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9505252e-01, 4.8595583e-03, 8.7971574e-05],\n",
       "       [4.8876952e-02, 9.4873106e-01, 2.3919328e-03],\n",
       "       [2.7355808e-04, 5.9800604e-03, 9.9374640e-01],\n",
       "       ...,\n",
       "       [1.7293771e-05, 9.9995613e-01, 2.6550935e-05],\n",
       "       [9.2015958e-05, 2.2420498e-05, 9.9988556e-01],\n",
       "       [5.4625657e-06, 2.7139100e-05, 9.9996746e-01]], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7d702479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fce8d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1=np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ceccca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 1, 0,\n",
       "       1, 1, 0, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 1, 0,\n",
       "       0, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 1,\n",
       "       2, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0,\n",
       "       1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 1, 1, 2, 1, 2, 0, 0,\n",
       "       1, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 0, 0, 1, 0,\n",
       "       2, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 1, 0,\n",
       "       0, 0, 0, 2, 1, 0, 1, 2, 2, 0, 2, 1, 0, 1, 2, 2, 0, 0, 2, 1, 2, 0,\n",
       "       0, 2, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1,\n",
       "       2, 0, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2,\n",
       "       2, 2, 1, 1, 0, 1, 2, 0, 2, 1, 2, 1, 1, 0, 0, 1, 0, 1, 0, 2, 2, 2,\n",
       "       2, 2, 1, 0, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1,\n",
       "       2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1,\n",
       "       1, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0,\n",
       "       2, 0, 1, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 2, 2, 2, 2, 1, 1,\n",
       "       0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 2, 2, 0, 0, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1,\n",
       "       0, 2, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       2, 0, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2,\n",
       "       0, 0, 2, 1, 0, 2, 1, 0, 1, 1, 1, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6e2dfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7f3ad834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0, 2, 2, 0, 1, 1, 2, 1, 0,\n",
       "       1, 1, 0, 2, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 0, 1, 0,\n",
       "       0, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 1,\n",
       "       2, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 0, 2, 1, 0, 1, 1, 1, 2, 0,\n",
       "       1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 2, 0, 0,\n",
       "       1, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 0, 2, 0, 0, 2, 0, 2,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 0, 0, 1, 0,\n",
       "       2, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 1, 0,\n",
       "       0, 0, 0, 2, 1, 0, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0,\n",
       "       0, 2, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1,\n",
       "       2, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 2,\n",
       "       2, 2, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2,\n",
       "       2, 2, 1, 0, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1,\n",
       "       2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1,\n",
       "       1, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 0, 0,\n",
       "       2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 2, 2, 2, 2, 1, 1,\n",
       "       0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1,\n",
       "       0, 2, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       2, 0, 2, 0, 2, 0, 2, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 2, 0, 1, 2,\n",
       "       0, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "87435ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8a81d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binarized=label_binarize(y_test1,classes=np.unique(y_test1))\n",
    "classes=np.unique(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0bf91249",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prednew=label_binarize(y_pred,classes=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8b875570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prednew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "98c109f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "203bb5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6e670657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test2=np.array(y_test)\n",
    "# y_pred1=np.array(pred)\n",
    "# y_final=np.concatenate((1-y_pred1,y_pred1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "02fc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bb2e5d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# roc curve for classes\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresh =dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "n_class = classes.shape[0]\n",
    "colors = ['yellow', 'red', 'green']\n",
    "\n",
    "for i, color in zip(range(n_class),colors):    \n",
    "    fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test[:,i],y_prednew[:,i])\n",
    "#     fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test2,y_final)\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # plotting    \n",
    "    plt.plot(fpr[i], tpr[i], linestyle='--',color=color, \n",
    "             label='%s vs Rest (AUC=%0.2f)'%(classes[i],roc_auc[i]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1.05])\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5c1f7843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154,  15,   1],\n",
       "       [  2, 160,   3],\n",
       "       [  0,   0, 163]], dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test1,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "21da2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94       170\n",
      "           1       0.91      0.97      0.94       165\n",
      "           2       0.98      1.00      0.99       163\n",
      "\n",
      "    accuracy                           0.96       498\n",
      "   macro avg       0.96      0.96      0.96       498\n",
      "weighted avg       0.96      0.96      0.96       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\\n\",classification_report(y_test1,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b1a58bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.78%\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_prednew)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1b35b856",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [146]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m(x_train, y_train)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# val_scores = model.evaluate(x_train, y_train)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(x_train, y_train)\n",
    "# val_scores = model.evaluate(x_train, y_train)\n",
    "test_scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
    "# print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc863abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729310797954546"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "auc = metrics.roc_auc_score(y_test, y_prednew, multi_class='ovo')\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
