{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf11c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fdd027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('mental-state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec6ae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.781648</td>\n",
       "      <td>33.836367</td>\n",
       "      <td>-92.769629</td>\n",
       "      <td>19.187957</td>\n",
       "      <td>-1.542262</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-119.561133</td>\n",
       "      <td>2.032654</td>\n",
       "      <td>21.596272</td>\n",
       "      <td>33.965587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.357891</td>\n",
       "      <td>26.792566</td>\n",
       "      <td>417.203910</td>\n",
       "      <td>19.472121</td>\n",
       "      <td>-38.797263</td>\n",
       "      <td>-16.897194</td>\n",
       "      <td>-29.368531</td>\n",
       "      <td>-9.055370</td>\n",
       "      <td>44.647424</td>\n",
       "      <td>40.893307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.451926</td>\n",
       "      <td>31.076434</td>\n",
       "      <td>72.231301</td>\n",
       "      <td>14.245938</td>\n",
       "      <td>-13.225057</td>\n",
       "      <td>-0.614138</td>\n",
       "      <td>-28.331698</td>\n",
       "      <td>-8.858742</td>\n",
       "      <td>31.450289</td>\n",
       "      <td>30.692883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.282184</td>\n",
       "      <td>19.985184</td>\n",
       "      <td>16.220094</td>\n",
       "      <td>39.787312</td>\n",
       "      <td>1.847866</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>-1.820355</td>\n",
       "      <td>20.220724</td>\n",
       "      <td>21.404679</td>\n",
       "      <td>20.777411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.431516</td>\n",
       "      <td>28.982168</td>\n",
       "      <td>27.540246</td>\n",
       "      <td>19.960398</td>\n",
       "      <td>2.491458</td>\n",
       "      <td>-6.020503</td>\n",
       "      <td>-1.071166</td>\n",
       "      <td>2.655259</td>\n",
       "      <td>16.295039</td>\n",
       "      <td>32.658163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0    25.781648    33.836367   -92.769629    19.187957           -1.542262   \n",
       "1    29.357891    26.792566   417.203910    19.472121          -38.797263   \n",
       "2    28.451926    31.076434    72.231301    14.245938          -13.225057   \n",
       "3    21.282184    19.985184    16.220094    39.787312            1.847866   \n",
       "4    20.431516    28.982168    27.540246    19.960398            2.491458   \n",
       "\n",
       "   lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  lag1_mean_q1_0  \\\n",
       "0            0.197462         -119.561133            2.032654       21.596272   \n",
       "1          -16.897194          -29.368531           -9.055370       44.647424   \n",
       "2           -0.614138          -28.331698           -8.858742       31.450289   \n",
       "3            0.670216           -1.820355           20.220724       21.404679   \n",
       "4           -6.020503           -1.071166            2.655259       16.295039   \n",
       "\n",
       "   lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  freq_699_3  \\\n",
       "0       33.965587  ...    0.000230    0.000351    0.000547    0.000381   \n",
       "1       40.893307  ...    0.001671    0.000740    0.001122    0.000521   \n",
       "2       30.692883  ...    0.000748    0.000569    0.000327    0.000197   \n",
       "3       20.777411  ...    0.000990    0.005644    0.006891    0.010546   \n",
       "4       32.658163  ...    0.001659    0.014379    0.014492    0.002949   \n",
       "\n",
       "   freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  Label  \n",
       "0    0.000350    0.000453    0.000442    0.000325    0.000209    2.0  \n",
       "1    0.000624    0.000439    0.001249    0.000727    0.000801    2.0  \n",
       "2    0.000833    0.000909    0.000699    0.001165    0.000616    2.0  \n",
       "3    0.009583    0.011158    0.008853    0.004551    0.002287    1.0  \n",
       "4    0.004575    0.008305    0.007202    0.006957    0.009836    2.0  \n",
       "\n",
       "[5 rows x 989 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509d4d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2479, 988)\n",
      "(2479,)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(['Label'],axis=1)\n",
    "y=df['Label'].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14f5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab037969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df39345",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3f728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e7e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-21.044050</td>\n",
       "      <td>-0.010535</td>\n",
       "      <td>0.718237</td>\n",
       "      <td>-2.682393</td>\n",
       "      <td>4.193227</td>\n",
       "      <td>-1.814457</td>\n",
       "      <td>1.506927</td>\n",
       "      <td>-7.564069</td>\n",
       "      <td>5.086254</td>\n",
       "      <td>-2.217937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560615</td>\n",
       "      <td>0.565428</td>\n",
       "      <td>0.781517</td>\n",
       "      <td>-0.223821</td>\n",
       "      <td>-1.647040</td>\n",
       "      <td>-0.354862</td>\n",
       "      <td>-0.106529</td>\n",
       "      <td>0.179565</td>\n",
       "      <td>0.767859</td>\n",
       "      <td>-1.606485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24.072607</td>\n",
       "      <td>-9.930574</td>\n",
       "      <td>-12.967207</td>\n",
       "      <td>2.545072</td>\n",
       "      <td>5.526551</td>\n",
       "      <td>-3.177310</td>\n",
       "      <td>-0.278590</td>\n",
       "      <td>1.138539</td>\n",
       "      <td>0.579483</td>\n",
       "      <td>1.883217</td>\n",
       "      <td>...</td>\n",
       "      <td>3.492633</td>\n",
       "      <td>2.443162</td>\n",
       "      <td>0.956267</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>-0.979943</td>\n",
       "      <td>-1.096413</td>\n",
       "      <td>-0.606057</td>\n",
       "      <td>1.221666</td>\n",
       "      <td>0.449532</td>\n",
       "      <td>2.880108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.926461</td>\n",
       "      <td>-3.452873</td>\n",
       "      <td>-3.501628</td>\n",
       "      <td>-1.068487</td>\n",
       "      <td>0.706277</td>\n",
       "      <td>2.762854</td>\n",
       "      <td>-2.036844</td>\n",
       "      <td>-2.407663</td>\n",
       "      <td>-1.345975</td>\n",
       "      <td>1.013190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088606</td>\n",
       "      <td>-0.913177</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.049523</td>\n",
       "      <td>-1.388717</td>\n",
       "      <td>-0.367880</td>\n",
       "      <td>-0.291916</td>\n",
       "      <td>0.356873</td>\n",
       "      <td>-0.411507</td>\n",
       "      <td>0.769915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.600035</td>\n",
       "      <td>-1.355738</td>\n",
       "      <td>1.934047</td>\n",
       "      <td>-1.049669</td>\n",
       "      <td>-1.309943</td>\n",
       "      <td>-1.622926</td>\n",
       "      <td>-0.501734</td>\n",
       "      <td>0.973511</td>\n",
       "      <td>-0.773587</td>\n",
       "      <td>-1.199486</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644177</td>\n",
       "      <td>0.605429</td>\n",
       "      <td>0.095845</td>\n",
       "      <td>-0.024603</td>\n",
       "      <td>-1.448505</td>\n",
       "      <td>0.489924</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>-1.057459</td>\n",
       "      <td>-0.077060</td>\n",
       "      <td>0.378207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.194237</td>\n",
       "      <td>23.783829</td>\n",
       "      <td>-8.415842</td>\n",
       "      <td>3.450492</td>\n",
       "      <td>-3.116790</td>\n",
       "      <td>1.795192</td>\n",
       "      <td>-0.232985</td>\n",
       "      <td>-0.756297</td>\n",
       "      <td>-5.876472</td>\n",
       "      <td>-1.407715</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034017</td>\n",
       "      <td>0.511270</td>\n",
       "      <td>-1.865554</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>-1.980606</td>\n",
       "      <td>-0.193428</td>\n",
       "      <td>2.163160</td>\n",
       "      <td>1.278912</td>\n",
       "      <td>3.449049</td>\n",
       "      <td>2.522226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>4.429953</td>\n",
       "      <td>2.463688</td>\n",
       "      <td>8.952368</td>\n",
       "      <td>-3.283096</td>\n",
       "      <td>2.224580</td>\n",
       "      <td>-0.406069</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>-2.090272</td>\n",
       "      <td>-0.197276</td>\n",
       "      <td>1.246928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121508</td>\n",
       "      <td>1.005361</td>\n",
       "      <td>-0.358701</td>\n",
       "      <td>-0.753647</td>\n",
       "      <td>-1.333987</td>\n",
       "      <td>-1.753526</td>\n",
       "      <td>1.145154</td>\n",
       "      <td>1.055852</td>\n",
       "      <td>-0.714314</td>\n",
       "      <td>-0.767876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>-15.184362</td>\n",
       "      <td>-3.404867</td>\n",
       "      <td>-3.098049</td>\n",
       "      <td>-2.575951</td>\n",
       "      <td>-0.832394</td>\n",
       "      <td>2.470178</td>\n",
       "      <td>0.274132</td>\n",
       "      <td>-3.531329</td>\n",
       "      <td>-4.816856</td>\n",
       "      <td>0.734989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497827</td>\n",
       "      <td>-0.670901</td>\n",
       "      <td>-1.928317</td>\n",
       "      <td>-0.363553</td>\n",
       "      <td>0.542046</td>\n",
       "      <td>0.339167</td>\n",
       "      <td>-1.146962</td>\n",
       "      <td>-0.218991</td>\n",
       "      <td>1.275000</td>\n",
       "      <td>0.159475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>-23.102483</td>\n",
       "      <td>-1.753680</td>\n",
       "      <td>-2.376915</td>\n",
       "      <td>-2.046216</td>\n",
       "      <td>2.382936</td>\n",
       "      <td>3.713046</td>\n",
       "      <td>2.985261</td>\n",
       "      <td>-6.272221</td>\n",
       "      <td>-0.820152</td>\n",
       "      <td>-1.288296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737869</td>\n",
       "      <td>-1.551824</td>\n",
       "      <td>-0.257716</td>\n",
       "      <td>-0.625766</td>\n",
       "      <td>-0.195224</td>\n",
       "      <td>0.535489</td>\n",
       "      <td>-2.631091</td>\n",
       "      <td>-0.237783</td>\n",
       "      <td>-0.653515</td>\n",
       "      <td>-0.173351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>-14.956246</td>\n",
       "      <td>-2.568777</td>\n",
       "      <td>-1.610102</td>\n",
       "      <td>-1.530920</td>\n",
       "      <td>-4.903744</td>\n",
       "      <td>-1.602938</td>\n",
       "      <td>0.144156</td>\n",
       "      <td>1.737914</td>\n",
       "      <td>1.484763</td>\n",
       "      <td>-2.665988</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.018955</td>\n",
       "      <td>-1.225424</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>1.295102</td>\n",
       "      <td>-1.557679</td>\n",
       "      <td>-1.142176</td>\n",
       "      <td>1.636577</td>\n",
       "      <td>-0.196389</td>\n",
       "      <td>-1.161520</td>\n",
       "      <td>0.257414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>-4.193660</td>\n",
       "      <td>3.770532</td>\n",
       "      <td>10.018155</td>\n",
       "      <td>8.134187</td>\n",
       "      <td>4.296994</td>\n",
       "      <td>-4.665702</td>\n",
       "      <td>-2.719872</td>\n",
       "      <td>1.532992</td>\n",
       "      <td>-2.650174</td>\n",
       "      <td>4.230502</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265790</td>\n",
       "      <td>-0.055762</td>\n",
       "      <td>0.940356</td>\n",
       "      <td>0.319097</td>\n",
       "      <td>1.222793</td>\n",
       "      <td>-0.527602</td>\n",
       "      <td>-1.060429</td>\n",
       "      <td>0.851352</td>\n",
       "      <td>-0.733678</td>\n",
       "      <td>-0.171275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2479 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2         3         4         5         6   \\\n",
       "0    -21.044050  -0.010535   0.718237 -2.682393  4.193227 -1.814457  1.506927   \n",
       "1    -24.072607  -9.930574 -12.967207  2.545072  5.526551 -3.177310 -0.278590   \n",
       "2    -22.926461  -3.452873  -3.501628 -1.068487  0.706277  2.762854 -2.036844   \n",
       "3      8.600035  -1.355738   1.934047 -1.049669 -1.309943 -1.622926 -0.501734   \n",
       "4     12.194237  23.783829  -8.415842  3.450492 -3.116790  1.795192 -0.232985   \n",
       "...         ...        ...        ...       ...       ...       ...       ...   \n",
       "2474   4.429953   2.463688   8.952368 -3.283096  2.224580 -0.406069  0.070482   \n",
       "2475 -15.184362  -3.404867  -3.098049 -2.575951 -0.832394  2.470178  0.274132   \n",
       "2476 -23.102483  -1.753680  -2.376915 -2.046216  2.382936  3.713046  2.985261   \n",
       "2477 -14.956246  -2.568777  -1.610102 -1.530920 -4.903744 -1.602938  0.144156   \n",
       "2478  -4.193660   3.770532  10.018155  8.134187  4.296994 -4.665702 -2.719872   \n",
       "\n",
       "            7         8         9   ...        54        55        56  \\\n",
       "0    -7.564069  5.086254 -2.217937  ...  0.560615  0.565428  0.781517   \n",
       "1     1.138539  0.579483  1.883217  ...  3.492633  2.443162  0.956267   \n",
       "2    -2.407663 -1.345975  1.013190  ...  0.088606 -0.913177  0.723997   \n",
       "3     0.973511 -0.773587 -1.199486  ... -1.644177  0.605429  0.095845   \n",
       "4    -0.756297 -5.876472 -1.407715  ... -1.034017  0.511270 -1.865554   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2474 -2.090272 -0.197276  1.246928  ...  2.121508  1.005361 -0.358701   \n",
       "2475 -3.531329 -4.816856  0.734989  ...  0.497827 -0.670901 -1.928317   \n",
       "2476 -6.272221 -0.820152 -1.288296  ... -0.737869 -1.551824 -0.257716   \n",
       "2477  1.737914  1.484763 -2.665988  ... -1.018955 -1.225424  0.150586   \n",
       "2478  1.532992 -2.650174  4.230502  ...  2.265790 -0.055762  0.940356   \n",
       "\n",
       "            57        58        59        60        61        62        63  \n",
       "0    -0.223821 -1.647040 -0.354862 -0.106529  0.179565  0.767859 -1.606485  \n",
       "1    -0.399467 -0.979943 -1.096413 -0.606057  1.221666  0.449532  2.880108  \n",
       "2     0.049523 -1.388717 -0.367880 -0.291916  0.356873 -0.411507  0.769915  \n",
       "3    -0.024603 -1.448505  0.489924  0.843662 -1.057459 -0.077060  0.378207  \n",
       "4     0.739003 -1.980606 -0.193428  2.163160  1.278912  3.449049  2.522226  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2474 -0.753647 -1.333987 -1.753526  1.145154  1.055852 -0.714314 -0.767876  \n",
       "2475 -0.363553  0.542046  0.339167 -1.146962 -0.218991  1.275000  0.159475  \n",
       "2476 -0.625766 -0.195224  0.535489 -2.631091 -0.237783 -0.653515 -0.173351  \n",
       "2477  1.295102 -1.557679 -1.142176  1.636577 -0.196389 -1.161520  0.257414  \n",
       "2478  0.319097  1.222793 -0.527602 -1.060429  0.851352 -0.733678 -0.171275  \n",
       "\n",
       "[2479 rows x 64 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca =pd.DataFrame(X_pca)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5beb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872d4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.concat([X_pca, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb849fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-21.044050</td>\n",
       "      <td>-0.010535</td>\n",
       "      <td>0.718237</td>\n",
       "      <td>-2.682393</td>\n",
       "      <td>4.193227</td>\n",
       "      <td>-1.814457</td>\n",
       "      <td>1.506927</td>\n",
       "      <td>-7.564069</td>\n",
       "      <td>5.086254</td>\n",
       "      <td>-2.217937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565428</td>\n",
       "      <td>0.781517</td>\n",
       "      <td>-0.223821</td>\n",
       "      <td>-1.647040</td>\n",
       "      <td>-0.354862</td>\n",
       "      <td>-0.106529</td>\n",
       "      <td>0.179565</td>\n",
       "      <td>0.767859</td>\n",
       "      <td>-1.606485</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24.072607</td>\n",
       "      <td>-9.930574</td>\n",
       "      <td>-12.967207</td>\n",
       "      <td>2.545072</td>\n",
       "      <td>5.526551</td>\n",
       "      <td>-3.177310</td>\n",
       "      <td>-0.278590</td>\n",
       "      <td>1.138539</td>\n",
       "      <td>0.579483</td>\n",
       "      <td>1.883217</td>\n",
       "      <td>...</td>\n",
       "      <td>2.443162</td>\n",
       "      <td>0.956267</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>-0.979943</td>\n",
       "      <td>-1.096413</td>\n",
       "      <td>-0.606057</td>\n",
       "      <td>1.221666</td>\n",
       "      <td>0.449532</td>\n",
       "      <td>2.880108</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.926461</td>\n",
       "      <td>-3.452873</td>\n",
       "      <td>-3.501628</td>\n",
       "      <td>-1.068487</td>\n",
       "      <td>0.706277</td>\n",
       "      <td>2.762854</td>\n",
       "      <td>-2.036844</td>\n",
       "      <td>-2.407663</td>\n",
       "      <td>-1.345975</td>\n",
       "      <td>1.013190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.913177</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.049523</td>\n",
       "      <td>-1.388717</td>\n",
       "      <td>-0.367880</td>\n",
       "      <td>-0.291916</td>\n",
       "      <td>0.356873</td>\n",
       "      <td>-0.411507</td>\n",
       "      <td>0.769915</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.600035</td>\n",
       "      <td>-1.355738</td>\n",
       "      <td>1.934047</td>\n",
       "      <td>-1.049669</td>\n",
       "      <td>-1.309943</td>\n",
       "      <td>-1.622926</td>\n",
       "      <td>-0.501734</td>\n",
       "      <td>0.973511</td>\n",
       "      <td>-0.773587</td>\n",
       "      <td>-1.199486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605429</td>\n",
       "      <td>0.095845</td>\n",
       "      <td>-0.024603</td>\n",
       "      <td>-1.448505</td>\n",
       "      <td>0.489924</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>-1.057459</td>\n",
       "      <td>-0.077060</td>\n",
       "      <td>0.378207</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.194237</td>\n",
       "      <td>23.783829</td>\n",
       "      <td>-8.415842</td>\n",
       "      <td>3.450492</td>\n",
       "      <td>-3.116790</td>\n",
       "      <td>1.795192</td>\n",
       "      <td>-0.232985</td>\n",
       "      <td>-0.756297</td>\n",
       "      <td>-5.876472</td>\n",
       "      <td>-1.407715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511270</td>\n",
       "      <td>-1.865554</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>-1.980606</td>\n",
       "      <td>-0.193428</td>\n",
       "      <td>2.163160</td>\n",
       "      <td>1.278912</td>\n",
       "      <td>3.449049</td>\n",
       "      <td>2.522226</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2         3         4         5         6   \\\n",
       "0 -21.044050  -0.010535   0.718237 -2.682393  4.193227 -1.814457  1.506927   \n",
       "1 -24.072607  -9.930574 -12.967207  2.545072  5.526551 -3.177310 -0.278590   \n",
       "2 -22.926461  -3.452873  -3.501628 -1.068487  0.706277  2.762854 -2.036844   \n",
       "3   8.600035  -1.355738   1.934047 -1.049669 -1.309943 -1.622926 -0.501734   \n",
       "4  12.194237  23.783829  -8.415842  3.450492 -3.116790  1.795192 -0.232985   \n",
       "\n",
       "         7         8         9   ...        55        56        57        58  \\\n",
       "0 -7.564069  5.086254 -2.217937  ...  0.565428  0.781517 -0.223821 -1.647040   \n",
       "1  1.138539  0.579483  1.883217  ...  2.443162  0.956267 -0.399467 -0.979943   \n",
       "2 -2.407663 -1.345975  1.013190  ... -0.913177  0.723997  0.049523 -1.388717   \n",
       "3  0.973511 -0.773587 -1.199486  ...  0.605429  0.095845 -0.024603 -1.448505   \n",
       "4 -0.756297 -5.876472 -1.407715  ...  0.511270 -1.865554  0.739003 -1.980606   \n",
       "\n",
       "         59        60        61        62        63   0   \n",
       "0 -0.354862 -0.106529  0.179565  0.767859 -1.606485  2.0  \n",
       "1 -1.096413 -0.606057  1.221666  0.449532  2.880108  2.0  \n",
       "2 -0.367880 -0.291916  0.356873 -0.411507  0.769915  2.0  \n",
       "3  0.489924  0.843662 -1.057459 -0.077060  0.378207  1.0  \n",
       "4 -0.193428  2.163160  1.278912  3.449049  2.522226  2.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef15bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_pca,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac11c73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1983, 64), (1983, 1), (496, 64), (496, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d2197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 60, 64)            384       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 60, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 30, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 64)            0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 30, 64)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 26, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 26, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling1d_3 (Averag  (None, 13, 64)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 13, 64)            0         \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 13, 64)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 833       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,297\n",
      "Trainable params: 55,041\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(64, 5, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "\n",
    "model.add(layers.Conv1D(64, 5,activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AvgPool1D(2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='softmax'))   \n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afa710e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 10s 112ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 3s 74ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 3s 67ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 3s 81ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 3s 78ms/step - loss: 0.0000e+00 - accuracy: 0.3302 - val_loss: 0.0000e+00 - val_accuracy: 0.3085\n",
      "Epoch 10/30\n",
      " 1/38 [..............................] - ETA: 2s - loss: 0.0000e+00 - accuracy: 0.4500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=40,epochs=30,verbose=1,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332791e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
